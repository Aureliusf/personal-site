{"meta":{"version":1,"warehouse":"6.0.0"},"models":{"Asset":[{"_id":"themes/minima/source/css/custom.css","path":"css/custom.css","modified":0,"renderable":1},{"_id":"themes/minima/source/css/normalize.css","path":"css/normalize.css","modified":0,"renderable":1},{"_id":"themes/minima/source/css/prism-dark.css","path":"css/prism-dark.css","modified":0,"renderable":1},{"_id":"themes/minima/source/css/prism-line-numbers.css","path":"css/prism-line-numbers.css","modified":0,"renderable":1},{"_id":"themes/minima/source/css/skeleton.css","path":"css/skeleton.css","modified":0,"renderable":1},{"_id":"themes/minima/source/fonts/dm-serif-display-v4-latin-regular.eot","path":"fonts/dm-serif-display-v4-latin-regular.eot","modified":0,"renderable":1},{"_id":"themes/minima/source/fonts/dm-serif-display-v4-latin-regular.svg","path":"fonts/dm-serif-display-v4-latin-regular.svg","modified":0,"renderable":1},{"_id":"themes/minima/source/fonts/dm-serif-display-v4-latin-regular.ttf","path":"fonts/dm-serif-display-v4-latin-regular.ttf","modified":0,"renderable":1},{"_id":"themes/minima/source/fonts/dm-serif-display-v4-latin-regular.woff","path":"fonts/dm-serif-display-v4-latin-regular.woff","modified":0,"renderable":1},{"_id":"themes/minima/source/fonts/dm-serif-display-v4-latin-regular.woff2","path":"fonts/dm-serif-display-v4-latin-regular.woff2","modified":0,"renderable":1},{"_id":"themes/minima/source/fonts/inter-v2-latin-regular.eot","path":"fonts/inter-v2-latin-regular.eot","modified":0,"renderable":1},{"_id":"themes/minima/source/fonts/inter-v2-latin-regular.svg","path":"fonts/inter-v2-latin-regular.svg","modified":0,"renderable":1},{"_id":"themes/minima/source/fonts/inter-v2-latin-regular.ttf","path":"fonts/inter-v2-latin-regular.ttf","modified":0,"renderable":1},{"_id":"themes/minima/source/fonts/inter-v2-latin-regular.woff","path":"fonts/inter-v2-latin-regular.woff","modified":0,"renderable":1},{"_id":"themes/minima/source/fonts/inter-v2-latin-regular.woff2","path":"fonts/inter-v2-latin-regular.woff2","modified":0,"renderable":1},{"_id":"themes/minima/source/images/epic-smiley.jpg","path":"images/epic-smiley.jpg","modified":0,"renderable":1},{"_id":"themes/minima/source/images/favicon.png","path":"images/favicon.png","modified":0,"renderable":1},{"_id":"themes/minima/source/images/thumbnail.jpg","path":"images/thumbnail.jpg","modified":0,"renderable":1},{"_id":"themes/minima/source/js/nanobar.min.js","path":"js/nanobar.min.js","modified":0,"renderable":1},{"_id":"source/Aurelio-Florez-resume.pdf","path":"Aurelio-Florez-resume.pdf","modified":0,"renderable":0},{"_id":"source/AurelioFlorez.pdf","path":"AurelioFlorez.pdf","modified":0,"renderable":0},{"_id":"source/images/900.png","path":"images/900.png","modified":0,"renderable":0},{"_id":"source/images/demo.png","path":"images/demo.png","modified":0,"renderable":0},{"_id":"source/images/longest.png","path":"images/longest.png","modified":0,"renderable":0},{"_id":"source/images/madam-x.png","path":"images/madam-x.png","modified":0,"renderable":0},{"_id":"source/images/examples/900.png","path":"images/examples/900.png","modified":0,"renderable":0},{"_id":"source/images/examples/longest.png","path":"images/examples/longest.png","modified":0,"renderable":0},{"_id":"source/images/examples/madam-x.png","path":"images/examples/madam-x.png","modified":0,"renderable":0}],"Cache":[{"_id":"source/_posts/Spotify-analyzer.md","hash":"1e2df4be4c5e7d4d3020979c9c3136022ec16fa4","modified":1758829380523},{"_id":"source/_posts/SEO-Twitter.md","hash":"6923487295c32fbd59006e0086d8decf57f15f03","modified":1758829380522},{"_id":"source/AurelioFlorez.pdf","hash":"d2f87a2345fb660c3d9f245267ea632db458705e","modified":1758829380522},{"_id":"source/_posts/Utility-Chrome-Extension.md","hash":"64342c54262d0a8096e3d0b099fff27d47861f05","modified":1758829380523},{"_id":"source/_posts/bo-tf.md","hash":"dfb4f219815fe48969275e4dfef17f612380f9d1","modified":1758829380523},{"_id":"source/images/demo.png","hash":"b30d6465f30100ae9c746ebe6cd837a6614d9d2e","modified":1758829380524},{"_id":"themes/minima/.gitignore","hash":"824c6bad36ef799350c37bcd0fe5a1a88295d2f8","modified":1758829380529},{"_id":"themes/minima/LICENSE","hash":"d31e0df078ff6f9bc2923196d9aae1cd50516159","modified":1758829380530},{"_id":"themes/minima/README.md","hash":"4dbaa7bb7697a0e984450c1497ad949f3165da9d","modified":1758829380530},{"_id":"source/Aurelio-Florez-resume.pdf","hash":"bc958a9ce94a2fb66f7d58d7975fd6ce2fa5bc99","modified":1758829380522},{"_id":"themes/minima/layout/archive.ejs","hash":"3ba1f33ed739039930b987b4c0f0977a46d63310","modified":1758829380530},{"_id":"themes/minima/layout/index.ejs","hash":"f61dafb2111339b20b6f147e670fa2a249c5cc8f","modified":1758829380530},{"_id":"themes/minima/layout/post.ejs","hash":"4ee26327a088fc043c5c8bfc3a4d44f4155364cb","modified":1758829380531},{"_id":"themes/minima/layout/page.ejs","hash":"ba59ed3ac4edd762029b31686f2d3b60ef7b943d","modified":1758829380530},{"_id":"themes/minima/_config.yml","hash":"2cea199af8deacae8185347e5a0326cb93afe6c8","modified":1758829723445},{"_id":"themes/minima/layout/partial/comments.ejs","hash":"827bced78b4ef972d1b70e4cb5b5171da6b0ed35","modified":1758829380530},{"_id":"themes/minima/layout/partial/google_analytics.ejs","hash":"0f9b2ebd8053e33c2a11976290dca5012f44cd46","modified":1758829380530},{"_id":"themes/minima/layout/layout.ejs","hash":"7362dec846b67d65bc01f36fa1765cfdf05a3603","modified":1758829380530},{"_id":"themes/minima/layout/partial/header.ejs","hash":"421bd87bab3e2a006153a2cf7dbc1cc69fb6ee97","modified":1758829380531},{"_id":"themes/minima/layout/partial/footer.ejs","hash":"f4cab46357adacd1cdbc5bf4329e03114ee75523","modified":1758829380530},{"_id":"themes/minima/layout/tag.ejs","hash":"c3a378abd79bc5d7b42af801845055e141e80fa1","modified":1758829380531},{"_id":"themes/minima/layout/partial/pagination.ejs","hash":"bce484c6ec05b3120c1aba49b64cd00b7a0afb2b","modified":1758829380531},{"_id":"themes/minima/layout/partial/tcolor.ejs","hash":"badfacb7abd8ab2e4732777177526a63b9b776f3","modified":1758829380531},{"_id":"themes/minima/source/css/prism-dark.css","hash":"b381cabf5fdfd9be4655aab61b4ef31273f0ea3c","modified":1758829380531},{"_id":"themes/minima/source/css/custom.css","hash":"ad2d58ce4c56e45844eb1dfa7dd35f0081aef657","modified":1758829380531},{"_id":"themes/minima/source/css/normalize.css","hash":"dd1976308129df19afb1a0dfdc9cc5d2aee7aec2","modified":1758829380531},{"_id":"themes/minima/source/css/prism-line-numbers.css","hash":"c632c3fa3fd97d05a0f74c6a87e1e93ee60ee57f","modified":1758829380531},{"_id":"themes/minima/source/css/skeleton.css","hash":"46633c4f03fc8de882077a141775a83f2dd6acc0","modified":1758829380531},{"_id":"themes/minima/source/fonts/dm-serif-display-v4-latin-regular.woff","hash":"61692ca29e433827e7c227e7d19a70037ff87273","modified":1758829380533},{"_id":"themes/minima/source/fonts/dm-serif-display-v4-latin-regular.ttf","hash":"1eaeb5d2d0a01f02cfd1313903b35bcef224d379","modified":1758829380532},{"_id":"themes/minima/source/fonts/dm-serif-display-v4-latin-regular.eot","hash":"7c5138328e9d4d2e231408c00eb879d1508a6f4e","modified":1758829380532},{"_id":"themes/minima/source/fonts/inter-v2-latin-regular.eot","hash":"b18f1e7b093bf71d833ddfd81676bdfbf165e810","modified":1758829380533},{"_id":"themes/minima/source/fonts/dm-serif-display-v4-latin-regular.woff2","hash":"c104f19b6f5176eae39be527c43742a236b9ac29","modified":1758829380533},{"_id":"themes/minima/source/fonts/inter-v2-latin-regular.woff","hash":"7f36fa1af7da1caa31a37e7b96c1772b75494726","modified":1758829380534},{"_id":"themes/minima/source/images/thumbnail.jpg","hash":"80248d23872a62ae51080920487adada35d3f5a2","modified":1758829380535},{"_id":"themes/minima/source/fonts/inter-v2-latin-regular.ttf","hash":"d96f19bfb5bd9e7b85f590c20960d0cb8a1fffcd","modified":1758829380533},{"_id":"themes/minima/source/fonts/inter-v2-latin-regular.svg","hash":"ca639a580d3dd7c1a023d489cd818af95883b52b","modified":1758829380533},{"_id":"themes/minima/source/fonts/inter-v2-latin-regular.woff2","hash":"99ad803462294f0cfce54995572d6caf8d955028","modified":1758829380534},{"_id":"themes/minima/source/images/favicon.png","hash":"7d18666e5a8455f4367b240425d617cf93966e10","modified":1758829380535},{"_id":"themes/minima/source/js/nanobar.min.js","hash":"a4f2199873bd6a386e75733fb44e244a0da09196","modified":1758829380535},{"_id":"source/images/900.png","hash":"8b8adef5dffd82bdec2a3e6551fd0f40b440aa5a","modified":1758829380524},{"_id":"themes/minima/source/fonts/dm-serif-display-v4-latin-regular.svg","hash":"b650647a506978c3617a12cb50ba3c4c596ee6e7","modified":1758829380532},{"_id":"source/images/madam-x.png","hash":"d1c456d5cd0c62ca4452e426d98398423152de8c","modified":1758829380529},{"_id":"source/images/examples/900.png","hash":"8b8adef5dffd82bdec2a3e6551fd0f40b440aa5a","modified":1758829380524},{"_id":"source/images/examples/madam-x.png","hash":"d1c456d5cd0c62ca4452e426d98398423152de8c","modified":1758829380527},{"_id":"source/images/longest.png","hash":"b843320c06b58331e1fb2291b57d625f2e0dc2ef","modified":1758829380528},{"_id":"themes/minima/source/images/epic-smiley.jpg","hash":"11102caf25def291217235fe403c15e9fd40f9e3","modified":1758829380535},{"_id":"source/images/examples/longest.png","hash":"b843320c06b58331e1fb2291b57d625f2e0dc2ef","modified":1758829380526},{"_id":"public/2021/09/02/SEO-Twitter/index.html","hash":"7d4fe5c820d5ea61ce099d4f46c0db1f75c627e8","modified":1763232761596},{"_id":"public/2021/03/26/Spotify-analyzer/index.html","hash":"722913f41fa033758df54f03d7eec625f1b6728c","modified":1763232761596},{"_id":"public/2020/02/12/Utility-Chrome-Extension/index.html","hash":"b5ef8d22a4d08dd38ec7bc435d71635da0a08a06","modified":1763232761596},{"_id":"public/2020/01/01/bo-tf/index.html","hash":"98430e8baa549edf5e32efeee1632058073772dc","modified":1763232761596},{"_id":"public/archives/index.html","hash":"210909d9fdc17a787986f42f975a48a20eb7ab37","modified":1763269369155},{"_id":"public/archives/2020/index.html","hash":"eb6222e0d7c4f8c34dd67e1ae1fef2f565ab1bed","modified":1763232761596},{"_id":"public/archives/2020/01/index.html","hash":"1491e4730f483952fd98b79b2ceadea6a77921b0","modified":1763232761596},{"_id":"public/archives/2020/02/index.html","hash":"341ed46d2f19105279eaeb658512772e0537633f","modified":1763232761596},{"_id":"public/archives/2021/index.html","hash":"4d9fad767b3e7ffa0e1d15dbc557fe116ffcf226","modified":1763232761596},{"_id":"public/archives/2021/03/index.html","hash":"d96fe3c55b67a0ff45e167c6fc93b28731e30ad3","modified":1763232761596},{"_id":"public/archives/2021/09/index.html","hash":"e23d684b2aa1fd713503505eeb511ae0b2c304c3","modified":1763232761596},{"_id":"public/index.html","hash":"56da8cc8b087c06847e7ba615372299e3b59eb99","modified":1763269369155},{"_id":"public/fonts/dm-serif-display-v4-latin-regular.eot","hash":"7c5138328e9d4d2e231408c00eb879d1508a6f4e","modified":1758830082723},{"_id":"public/fonts/dm-serif-display-v4-latin-regular.woff","hash":"61692ca29e433827e7c227e7d19a70037ff87273","modified":1758830082723},{"_id":"public/fonts/dm-serif-display-v4-latin-regular.ttf","hash":"1eaeb5d2d0a01f02cfd1313903b35bcef224d379","modified":1758830082723},{"_id":"public/fonts/dm-serif-display-v4-latin-regular.woff2","hash":"c104f19b6f5176eae39be527c43742a236b9ac29","modified":1758830082723},{"_id":"public/fonts/inter-v2-latin-regular.eot","hash":"b18f1e7b093bf71d833ddfd81676bdfbf165e810","modified":1758830082723},{"_id":"public/fonts/inter-v2-latin-regular.woff","hash":"7f36fa1af7da1caa31a37e7b96c1772b75494726","modified":1758830082723},{"_id":"public/fonts/inter-v2-latin-regular.svg","hash":"ca639a580d3dd7c1a023d489cd818af95883b52b","modified":1758830082723},{"_id":"public/fonts/inter-v2-latin-regular.ttf","hash":"d96f19bfb5bd9e7b85f590c20960d0cb8a1fffcd","modified":1758830082723},{"_id":"public/fonts/inter-v2-latin-regular.woff2","hash":"99ad803462294f0cfce54995572d6caf8d955028","modified":1758830082723},{"_id":"public/images/favicon.png","hash":"7d18666e5a8455f4367b240425d617cf93966e10","modified":1758830082723},{"_id":"public/images/thumbnail.jpg","hash":"80248d23872a62ae51080920487adada35d3f5a2","modified":1758830082723},{"_id":"public/images/demo.png","hash":"b30d6465f30100ae9c746ebe6cd837a6614d9d2e","modified":1758830082723},{"_id":"public/AurelioFlorez.pdf","hash":"d2f87a2345fb660c3d9f245267ea632db458705e","modified":1758830082723},{"_id":"public/fonts/dm-serif-display-v4-latin-regular.svg","hash":"b650647a506978c3617a12cb50ba3c4c596ee6e7","modified":1758830082723},{"_id":"public/css/custom.css","hash":"ad2d58ce4c56e45844eb1dfa7dd35f0081aef657","modified":1758830082723},{"_id":"public/css/prism-dark.css","hash":"b381cabf5fdfd9be4655aab61b4ef31273f0ea3c","modified":1758830082723},{"_id":"public/css/prism-line-numbers.css","hash":"c632c3fa3fd97d05a0f74c6a87e1e93ee60ee57f","modified":1758830082723},{"_id":"public/css/normalize.css","hash":"dd1976308129df19afb1a0dfdc9cc5d2aee7aec2","modified":1758830082723},{"_id":"public/js/nanobar.min.js","hash":"a4f2199873bd6a386e75733fb44e244a0da09196","modified":1758830082723},{"_id":"public/css/skeleton.css","hash":"46633c4f03fc8de882077a141775a83f2dd6acc0","modified":1758830082723},{"_id":"public/Aurelio-Florez-resume.pdf","hash":"bc958a9ce94a2fb66f7d58d7975fd6ce2fa5bc99","modified":1758830082723},{"_id":"public/images/epic-smiley.jpg","hash":"11102caf25def291217235fe403c15e9fd40f9e3","modified":1758830082723},{"_id":"public/images/900.png","hash":"8b8adef5dffd82bdec2a3e6551fd0f40b440aa5a","modified":1758830082723},{"_id":"public/images/madam-x.png","hash":"d1c456d5cd0c62ca4452e426d98398423152de8c","modified":1758830082723},{"_id":"public/images/examples/900.png","hash":"8b8adef5dffd82bdec2a3e6551fd0f40b440aa5a","modified":1758830082723},{"_id":"public/images/examples/madam-x.png","hash":"d1c456d5cd0c62ca4452e426d98398423152de8c","modified":1758830082723},{"_id":"public/images/longest.png","hash":"b843320c06b58331e1fb2291b57d625f2e0dc2ef","modified":1758830082723},{"_id":"public/images/examples/longest.png","hash":"b843320c06b58331e1fb2291b57d625f2e0dc2ef","modified":1758830082723},{"_id":"source/_posts/nixOS.md","hash":"15886fa3953af013f9dc103afd3bf89e8c6005d8","modified":1762142872762},{"_id":"public/archives/2025/index.html","hash":"49ac4214320a4909bb346c5621059946aae8b5f8","modified":1763269369155},{"_id":"public/archives/2025/06/index.html","hash":"e366d019fa1a273f9ffd5cbc33668b7df3be67bb","modified":1763232761596},{"_id":"public/2025/06/25/nixOS/index.html","hash":"889da4492ce3067cdb9d2ca19bf9b0150adb1547","modified":1763232761596},{"_id":"source/_posts/saradm.com-Fashion-Portfolio-Site.md","hash":"435050fbef0924844d3dff5a8ad132d4426bbe67","modified":1763271510036},{"_id":"public/2025/11/14/saradm.com-Fashion-Portfolio-Site/index.html","hash":"e56a1fd29b66292be1fbaa43ca38958fef592e0c","modified":1763180723936},{"_id":"public/archives/2025/11/index.html","hash":"76b2672f63d067819c2549fc43d1eef6beca4ea3","modified":1763269369155},{"_id":"source/.DS_Store","hash":"cc75fbdb977a72e3c33a32b977ec965c1597d5c5","modified":1763180932498},{"_id":"public/2025/11/10/saradm.com-Fashion-Portfolio-Site/index.html","hash":"3bacd4a5c99d029aa76b198b28a912ee1db63992","modified":1763271519784}],"Category":[],"Data":[],"Page":[],"Post":[{"title":"SEO-Twitter","date":"2021-09-03T00:33:52.000Z","_content":"This project has been in the dark for almost a year, waiting for fact-checked results. SEO-Twitter is a Twitter botnet with the only objective of generating seem-able \"organic links\" in social media.\n\n## Linkbuilding\n\nLinkbuilding is not something new, people have been doing it for a long time, but it usually involves paying another webmaster for links in recognized websites or posts in other blogs.\n\n> Link-juice coming from social media has a **disproportional weight** in your overall page ranking. \n\nI guess Google thinks that if social media is talking about you and linking you, it's because it's from real people. And even if they try to patch this, they will have a bad time generating their spam score for each account or trying to get it from Twitter.\n\n## Ways this can go wrong\n\nThere are **a lot**  of ways this can fail. If your website gets declared as spam by Twitter, everything you did falls, and you'll get punished with removed links, and your page may go down. \nThat is why it is essential to fine-tune your botnet not to get banned.\n\nThat is why it is so important to fine tune your botnet not to get banned.\n\n## Implementing\n\nImplementing [Twitter's API](https://developer.twitter.com/en/docs/twitter-api) is fairly easy with one account; if you want to do it with multiple, you'll have to have a database with all the credentials for each account. And don't get me started with generating all the credentials for every account üôÑ. \n\nI used a python wrapper for Twitter's API, simply called [twitter](https://pypi.org/project/twitter/). With this, you only need to give it the correct credentials and my content to publish tweets.\n\nJust like this:\n~~~python\nt = Twitter(auth=OAuth(token, token_secret , common_token, common_secret))\nt.statuses.update(status=tweet)\n~~~\n\nNow you'll need a connection with your credentials database. I stored token, and token_secret that are unique to each account with the account name as key and an epoch time of the last time they tweeted for not getting banned purposes.\n\nWith all that set, now the script will look something like this:\n~~~python\nwhile True:\n    for n in account_n:\n        credentials = get_credentials(n);\n\n        if (credentials['last_time']-time.time()< not_get_banned_time):\n\n            t = Twitter(auth=OAuth(credentials['token'], credentials['token_secret'] , common_token, common_secret))\n            t.statuses.update(status=tweet)\n\n~~~\nYou'll want to add exceptions to your code, so it still runs even if Twitter is down or something goes wrong.\n~~~python\nwhile True:\n    for n in account_n:\n        credentials = get_credentials(n);\n\n        if (credentials['last_time']-time.time()< not_get_banned_time):\n            try:\n                t = Twitter(auth=OAuth(credentials['token'], credentials['token_secret'] , common_token, common_secret))\n                t.statuses.update(status=tweet)\n            except:\n                print('something went wrong')\n                print(credentials['account_name'],\"has problems\")\n        else:\n            time.sleep(some_sensible_time)\n\n~~~\n\nNow let's talk about that `not_get_banned_time`. Twitter would not tell anyone exact numbers on how much you can publish without getting banned for spam. They probably don‚Äôt have a hardcode number. News accounts are posting every minute and don‚Äôt get banned. For the rest of us mortals without special contracts, the word in the street is that you can publish every two hours wihtout getting worried.\n\nYou‚Äôll need to send a tweet on each account every two hours or 7200 seconds for maximum efficiency. Twitter‚Äôs API is rate-limited at 1000 tweets an hour. If you do the math, that means you can support a theoretical 2000 accounts in only one developer account. I think you‚Äôll hit other limits first, though.\n\nFor getting that `not_get_banned_time` you need to divide 7200 by the number of accounts. So for 3 accounts, your script will publish every 2400s, and each account will publish every 7200s. This math is theoretical; add 2.3s or so for every publishing, but that only gets us in a safer spot.\n\n~~~python\n    not_get_banned_time = 7200/account_n\n~~~\n\n## Cover your back\n\nDoing this strategy carries its problems; you‚Äôll need to have some things in mind for mitigating possible issues.\n+ Cover your website with URL shorteners.\n        They let link juice pass but will cover you from spam filters.\n+ Do not use duplicate URLs every time.\n        To avoid spam filters, you can use multiple face URLs that go to the same URL.\n\n## Results\n\nI used this strategy in the best site possible, a large eCommerce moneysite. \n>The store started with 60k products and 15k pages listed and now a year later the same store has 90k products and 70k pages listed.\n\nAlmost 50k tweets were created and published over an entire year. Tweets content consisted of big keywords relevant to each unique product and a link to the product page.\n\n*Disclaimer: All the accounts used and will be used are **not compromised accounts** or in any shape or form, not mine. Please don‚Äôt do anything illegal; thanks <3.\n","source":"_posts/SEO-Twitter.md","raw":"---\ntitle: SEO-Twitter\ndate: 2021-09-02 20:33:52\ntags:\n---\nThis project has been in the dark for almost a year, waiting for fact-checked results. SEO-Twitter is a Twitter botnet with the only objective of generating seem-able \"organic links\" in social media.\n\n## Linkbuilding\n\nLinkbuilding is not something new, people have been doing it for a long time, but it usually involves paying another webmaster for links in recognized websites or posts in other blogs.\n\n> Link-juice coming from social media has a **disproportional weight** in your overall page ranking. \n\nI guess Google thinks that if social media is talking about you and linking you, it's because it's from real people. And even if they try to patch this, they will have a bad time generating their spam score for each account or trying to get it from Twitter.\n\n## Ways this can go wrong\n\nThere are **a lot**  of ways this can fail. If your website gets declared as spam by Twitter, everything you did falls, and you'll get punished with removed links, and your page may go down. \nThat is why it is essential to fine-tune your botnet not to get banned.\n\nThat is why it is so important to fine tune your botnet not to get banned.\n\n## Implementing\n\nImplementing [Twitter's API](https://developer.twitter.com/en/docs/twitter-api) is fairly easy with one account; if you want to do it with multiple, you'll have to have a database with all the credentials for each account. And don't get me started with generating all the credentials for every account üôÑ. \n\nI used a python wrapper for Twitter's API, simply called [twitter](https://pypi.org/project/twitter/). With this, you only need to give it the correct credentials and my content to publish tweets.\n\nJust like this:\n~~~python\nt = Twitter(auth=OAuth(token, token_secret , common_token, common_secret))\nt.statuses.update(status=tweet)\n~~~\n\nNow you'll need a connection with your credentials database. I stored token, and token_secret that are unique to each account with the account name as key and an epoch time of the last time they tweeted for not getting banned purposes.\n\nWith all that set, now the script will look something like this:\n~~~python\nwhile True:\n    for n in account_n:\n        credentials = get_credentials(n);\n\n        if (credentials['last_time']-time.time()< not_get_banned_time):\n\n            t = Twitter(auth=OAuth(credentials['token'], credentials['token_secret'] , common_token, common_secret))\n            t.statuses.update(status=tweet)\n\n~~~\nYou'll want to add exceptions to your code, so it still runs even if Twitter is down or something goes wrong.\n~~~python\nwhile True:\n    for n in account_n:\n        credentials = get_credentials(n);\n\n        if (credentials['last_time']-time.time()< not_get_banned_time):\n            try:\n                t = Twitter(auth=OAuth(credentials['token'], credentials['token_secret'] , common_token, common_secret))\n                t.statuses.update(status=tweet)\n            except:\n                print('something went wrong')\n                print(credentials['account_name'],\"has problems\")\n        else:\n            time.sleep(some_sensible_time)\n\n~~~\n\nNow let's talk about that `not_get_banned_time`. Twitter would not tell anyone exact numbers on how much you can publish without getting banned for spam. They probably don‚Äôt have a hardcode number. News accounts are posting every minute and don‚Äôt get banned. For the rest of us mortals without special contracts, the word in the street is that you can publish every two hours wihtout getting worried.\n\nYou‚Äôll need to send a tweet on each account every two hours or 7200 seconds for maximum efficiency. Twitter‚Äôs API is rate-limited at 1000 tweets an hour. If you do the math, that means you can support a theoretical 2000 accounts in only one developer account. I think you‚Äôll hit other limits first, though.\n\nFor getting that `not_get_banned_time` you need to divide 7200 by the number of accounts. So for 3 accounts, your script will publish every 2400s, and each account will publish every 7200s. This math is theoretical; add 2.3s or so for every publishing, but that only gets us in a safer spot.\n\n~~~python\n    not_get_banned_time = 7200/account_n\n~~~\n\n## Cover your back\n\nDoing this strategy carries its problems; you‚Äôll need to have some things in mind for mitigating possible issues.\n+ Cover your website with URL shorteners.\n        They let link juice pass but will cover you from spam filters.\n+ Do not use duplicate URLs every time.\n        To avoid spam filters, you can use multiple face URLs that go to the same URL.\n\n## Results\n\nI used this strategy in the best site possible, a large eCommerce moneysite. \n>The store started with 60k products and 15k pages listed and now a year later the same store has 90k products and 70k pages listed.\n\nAlmost 50k tweets were created and published over an entire year. Tweets content consisted of big keywords relevant to each unique product and a link to the product page.\n\n*Disclaimer: All the accounts used and will be used are **not compromised accounts** or in any shape or form, not mine. Please don‚Äôt do anything illegal; thanks <3.\n","slug":"SEO-Twitter","published":1,"updated":"2025-09-25T19:43:00.522Z","comments":1,"layout":"post","photos":[],"_id":"cuidgBT-Ce23FC1DmLbbweWIm","content":"<p>This project has been in the dark for almost a year, waiting for fact-checked results. SEO-Twitter is a Twitter botnet with the only objective of generating seem-able ‚Äúorganic links‚Äù in social media.</p>\n<h2 id=\"Linkbuilding\"><a href=\"#Linkbuilding\" class=\"headerlink\" title=\"Linkbuilding\"></a>Linkbuilding</h2><p>Linkbuilding is not something new, people have been doing it for a long time, but it usually involves paying another webmaster for links in recognized websites or posts in other blogs.</p>\n<blockquote>\n<p>Link-juice coming from social media has a <strong>disproportional weight</strong> in your overall page ranking. </p>\n</blockquote>\n<p>I guess Google thinks that if social media is talking about you and linking you, it‚Äôs because it‚Äôs from real people. And even if they try to patch this, they will have a bad time generating their spam score for each account or trying to get it from Twitter.</p>\n<h2 id=\"Ways-this-can-go-wrong\"><a href=\"#Ways-this-can-go-wrong\" class=\"headerlink\" title=\"Ways this can go wrong\"></a>Ways this can go wrong</h2><p>There are <strong>a lot</strong>  of ways this can fail. If your website gets declared as spam by Twitter, everything you did falls, and you‚Äôll get punished with removed links, and your page may go down.<br>That is why it is essential to fine-tune your botnet not to get banned.</p>\n<p>That is why it is so important to fine tune your botnet not to get banned.</p>\n<h2 id=\"Implementing\"><a href=\"#Implementing\" class=\"headerlink\" title=\"Implementing\"></a>Implementing</h2><p>Implementing <a href=\"https://developer.twitter.com/en/docs/twitter-api\">Twitter‚Äôs API</a> is fairly easy with one account; if you want to do it with multiple, you‚Äôll have to have a database with all the credentials for each account. And don‚Äôt get me started with generating all the credentials for every account üôÑ. </p>\n<p>I used a python wrapper for Twitter‚Äôs API, simply called <a href=\"https://pypi.org/project/twitter/\">twitter</a>. With this, you only need to give it the correct credentials and my content to publish tweets.</p>\n<p>Just like this:</p>\n<pre><code class=\"highlight python\">t = Twitter(auth=OAuth(token, token_secret , common_token, common_secret))\nt.statuses.update(status=tweet)</code></pre>\n\n<p>Now you‚Äôll need a connection with your credentials database. I stored token, and token_secret that are unique to each account with the account name as key and an epoch time of the last time they tweeted for not getting banned purposes.</p>\n<p>With all that set, now the script will look something like this:</p>\n<pre><code class=\"highlight python\"><span class=\"keyword\">while</span> <span class=\"literal\">True</span>:\n    <span class=\"keyword\">for</span> n <span class=\"keyword\">in</span> account_n:\n        credentials = get_credentials(n);\n\n        <span class=\"keyword\">if</span> (credentials[<span class=\"string\">&#x27;last_time&#x27;</span>]-time.time()&lt; not_get_banned_time):\n\n            t = Twitter(auth=OAuth(credentials[<span class=\"string\">&#x27;token&#x27;</span>], credentials[<span class=\"string\">&#x27;token_secret&#x27;</span>] , common_token, common_secret))\n            t.statuses.update(status=tweet)\n</code></pre>\n<p>You‚Äôll want to add exceptions to your code, so it still runs even if Twitter is down or something goes wrong.</p>\n<pre><code class=\"highlight python\"><span class=\"keyword\">while</span> <span class=\"literal\">True</span>:\n    <span class=\"keyword\">for</span> n <span class=\"keyword\">in</span> account_n:\n        credentials = get_credentials(n);\n\n        <span class=\"keyword\">if</span> (credentials[<span class=\"string\">&#x27;last_time&#x27;</span>]-time.time()&lt; not_get_banned_time):\n            <span class=\"keyword\">try</span>:\n                t = Twitter(auth=OAuth(credentials[<span class=\"string\">&#x27;token&#x27;</span>], credentials[<span class=\"string\">&#x27;token_secret&#x27;</span>] , common_token, common_secret))\n                t.statuses.update(status=tweet)\n            <span class=\"keyword\">except</span>:\n                <span class=\"built_in\">print</span>(<span class=\"string\">&#x27;something went wrong&#x27;</span>)\n                <span class=\"built_in\">print</span>(credentials[<span class=\"string\">&#x27;account_name&#x27;</span>],<span class=\"string\">&quot;has problems&quot;</span>)\n        <span class=\"keyword\">else</span>:\n            time.sleep(some_sensible_time)\n</code></pre>\n\n<p>Now let‚Äôs talk about that <code>not_get_banned_time</code>. Twitter would not tell anyone exact numbers on how much you can publish without getting banned for spam. They probably don‚Äôt have a hardcode number. News accounts are posting every minute and don‚Äôt get banned. For the rest of us mortals without special contracts, the word in the street is that you can publish every two hours wihtout getting worried.</p>\n<p>You‚Äôll need to send a tweet on each account every two hours or 7200 seconds for maximum efficiency. Twitter‚Äôs API is rate-limited at 1000 tweets an hour. If you do the math, that means you can support a theoretical 2000 accounts in only one developer account. I think you‚Äôll hit other limits first, though.</p>\n<p>For getting that <code>not_get_banned_time</code> you need to divide 7200 by the number of accounts. So for 3 accounts, your script will publish every 2400s, and each account will publish every 7200s. This math is theoretical; add 2.3s or so for every publishing, but that only gets us in a safer spot.</p>\n<pre><code class=\"highlight python\">not_get_banned_time = <span class=\"number\">7200</span>/account_n</code></pre>\n\n<h2 id=\"Cover-your-back\"><a href=\"#Cover-your-back\" class=\"headerlink\" title=\"Cover your back\"></a>Cover your back</h2><p>Doing this strategy carries its problems; you‚Äôll need to have some things in mind for mitigating possible issues.</p>\n<ul>\n<li>Cover your website with URL shorteners.<br>  They let link juice pass but will cover you from spam filters.</li>\n<li>Do not use duplicate URLs every time.<br>  To avoid spam filters, you can use multiple face URLs that go to the same URL.</li>\n</ul>\n<h2 id=\"Results\"><a href=\"#Results\" class=\"headerlink\" title=\"Results\"></a>Results</h2><p>I used this strategy in the best site possible, a large eCommerce moneysite. </p>\n<blockquote>\n<p>The store started with 60k products and 15k pages listed and now a year later the same store has 90k products and 70k pages listed.</p>\n</blockquote>\n<p>Almost 50k tweets were created and published over an entire year. Tweets content consisted of big keywords relevant to each unique product and a link to the product page.</p>\n<p>*Disclaimer: All the accounts used and will be used are <strong>not compromised accounts</strong> or in any shape or form, not mine. Please don‚Äôt do anything illegal; thanks &lt;3.</p>\n","excerpt":"","more":"<p>This project has been in the dark for almost a year, waiting for fact-checked results. SEO-Twitter is a Twitter botnet with the only objective of generating seem-able ‚Äúorganic links‚Äù in social media.</p>\n<h2 id=\"Linkbuilding\"><a href=\"#Linkbuilding\" class=\"headerlink\" title=\"Linkbuilding\"></a>Linkbuilding</h2><p>Linkbuilding is not something new, people have been doing it for a long time, but it usually involves paying another webmaster for links in recognized websites or posts in other blogs.</p>\n<blockquote>\n<p>Link-juice coming from social media has a <strong>disproportional weight</strong> in your overall page ranking. </p>\n</blockquote>\n<p>I guess Google thinks that if social media is talking about you and linking you, it‚Äôs because it‚Äôs from real people. And even if they try to patch this, they will have a bad time generating their spam score for each account or trying to get it from Twitter.</p>\n<h2 id=\"Ways-this-can-go-wrong\"><a href=\"#Ways-this-can-go-wrong\" class=\"headerlink\" title=\"Ways this can go wrong\"></a>Ways this can go wrong</h2><p>There are <strong>a lot</strong>  of ways this can fail. If your website gets declared as spam by Twitter, everything you did falls, and you‚Äôll get punished with removed links, and your page may go down.<br>That is why it is essential to fine-tune your botnet not to get banned.</p>\n<p>That is why it is so important to fine tune your botnet not to get banned.</p>\n<h2 id=\"Implementing\"><a href=\"#Implementing\" class=\"headerlink\" title=\"Implementing\"></a>Implementing</h2><p>Implementing <a href=\"https://developer.twitter.com/en/docs/twitter-api\">Twitter‚Äôs API</a> is fairly easy with one account; if you want to do it with multiple, you‚Äôll have to have a database with all the credentials for each account. And don‚Äôt get me started with generating all the credentials for every account üôÑ. </p>\n<p>I used a python wrapper for Twitter‚Äôs API, simply called <a href=\"https://pypi.org/project/twitter/\">twitter</a>. With this, you only need to give it the correct credentials and my content to publish tweets.</p>\n<p>Just like this:</p>\n<pre><code class=\"highlight python\">t = Twitter(auth=OAuth(token, token_secret , common_token, common_secret))\nt.statuses.update(status=tweet)</code></pre>\n\n<p>Now you‚Äôll need a connection with your credentials database. I stored token, and token_secret that are unique to each account with the account name as key and an epoch time of the last time they tweeted for not getting banned purposes.</p>\n<p>With all that set, now the script will look something like this:</p>\n<pre><code class=\"highlight python\"><span class=\"keyword\">while</span> <span class=\"literal\">True</span>:\n    <span class=\"keyword\">for</span> n <span class=\"keyword\">in</span> account_n:\n        credentials = get_credentials(n);\n\n        <span class=\"keyword\">if</span> (credentials[<span class=\"string\">&#x27;last_time&#x27;</span>]-time.time()&lt; not_get_banned_time):\n\n            t = Twitter(auth=OAuth(credentials[<span class=\"string\">&#x27;token&#x27;</span>], credentials[<span class=\"string\">&#x27;token_secret&#x27;</span>] , common_token, common_secret))\n            t.statuses.update(status=tweet)\n</code></pre>\n<p>You‚Äôll want to add exceptions to your code, so it still runs even if Twitter is down or something goes wrong.</p>\n<pre><code class=\"highlight python\"><span class=\"keyword\">while</span> <span class=\"literal\">True</span>:\n    <span class=\"keyword\">for</span> n <span class=\"keyword\">in</span> account_n:\n        credentials = get_credentials(n);\n\n        <span class=\"keyword\">if</span> (credentials[<span class=\"string\">&#x27;last_time&#x27;</span>]-time.time()&lt; not_get_banned_time):\n            <span class=\"keyword\">try</span>:\n                t = Twitter(auth=OAuth(credentials[<span class=\"string\">&#x27;token&#x27;</span>], credentials[<span class=\"string\">&#x27;token_secret&#x27;</span>] , common_token, common_secret))\n                t.statuses.update(status=tweet)\n            <span class=\"keyword\">except</span>:\n                <span class=\"built_in\">print</span>(<span class=\"string\">&#x27;something went wrong&#x27;</span>)\n                <span class=\"built_in\">print</span>(credentials[<span class=\"string\">&#x27;account_name&#x27;</span>],<span class=\"string\">&quot;has problems&quot;</span>)\n        <span class=\"keyword\">else</span>:\n            time.sleep(some_sensible_time)\n</code></pre>\n\n<p>Now let‚Äôs talk about that <code>not_get_banned_time</code>. Twitter would not tell anyone exact numbers on how much you can publish without getting banned for spam. They probably don‚Äôt have a hardcode number. News accounts are posting every minute and don‚Äôt get banned. For the rest of us mortals without special contracts, the word in the street is that you can publish every two hours wihtout getting worried.</p>\n<p>You‚Äôll need to send a tweet on each account every two hours or 7200 seconds for maximum efficiency. Twitter‚Äôs API is rate-limited at 1000 tweets an hour. If you do the math, that means you can support a theoretical 2000 accounts in only one developer account. I think you‚Äôll hit other limits first, though.</p>\n<p>For getting that <code>not_get_banned_time</code> you need to divide 7200 by the number of accounts. So for 3 accounts, your script will publish every 2400s, and each account will publish every 7200s. This math is theoretical; add 2.3s or so for every publishing, but that only gets us in a safer spot.</p>\n<pre><code class=\"highlight python\">not_get_banned_time = <span class=\"number\">7200</span>/account_n</code></pre>\n\n<h2 id=\"Cover-your-back\"><a href=\"#Cover-your-back\" class=\"headerlink\" title=\"Cover your back\"></a>Cover your back</h2><p>Doing this strategy carries its problems; you‚Äôll need to have some things in mind for mitigating possible issues.</p>\n<ul>\n<li>Cover your website with URL shorteners.<br>  They let link juice pass but will cover you from spam filters.</li>\n<li>Do not use duplicate URLs every time.<br>  To avoid spam filters, you can use multiple face URLs that go to the same URL.</li>\n</ul>\n<h2 id=\"Results\"><a href=\"#Results\" class=\"headerlink\" title=\"Results\"></a>Results</h2><p>I used this strategy in the best site possible, a large eCommerce moneysite. </p>\n<blockquote>\n<p>The store started with 60k products and 15k pages listed and now a year later the same store has 90k products and 70k pages listed.</p>\n</blockquote>\n<p>Almost 50k tweets were created and published over an entire year. Tweets content consisted of big keywords relevant to each unique product and a link to the product page.</p>\n<p>*Disclaimer: All the accounts used and will be used are <strong>not compromised accounts</strong> or in any shape or form, not mine. Please don‚Äôt do anything illegal; thanks &lt;3.</p>\n"},{"title":"Spotify-analyzer","date":"2021-03-27T00:43:42.000Z","_content":"# Spotify-analyzer\n This is a program that analyzes entire albums with [Spotify's stats](https://developer.spotify.com/documentation/web-api/reference/tracks/get-several-audio-features/).\n\nThis is an example of the [900](https://open.spotify.com/album/3yj1EziuVuch1OayyM95az?si=Z6Uzb4IXTl6ld2-9Ti2ubA) album. It shows the best song in each category in the subplot title and a legend at the bottom.\n![900](/images/examples/900.png)\n\n\n# Roadmap\n‚Ä¢ Make it get the album if you enter an individual song\n\n‚Ä¢ Usable for playlists and singles\n\n‚Ä¢ Make it compare in between albums\n\n‚Ä¢ Get conclusions in between albums\n\n‚Ä¢ Get popularity numbers and cross them with the audio features\n\n    ‚Ä¢ Get it to next level ideas:\n\n     ‚Ä¢ Get this into a backend and do it in a web server\n\n     ‚Ä¢ Make it public to use\n\n# More examples\n\nFor a large album, [Madam X](https://open.spotify.com/album/1G2YEQPXaOj1JZwa3ZiGe8?si=YA4YSD9MR6SlNerjUM2gcQ):\n![Madam-X](/images/examples/madam-x.png)\n\n\nFor the longest album I could find, [Ella Fitzgerald Sings The George And Ira Gershwin Song Book](https://open.spotify.com/album/2vz9bOelnO5EoDBPkzEJjt?si=6xp-6ifPQGusfzhjRA8o7g):\n\n![Ella-Fitzgerald-Sings-The-George-And-Ira-Gershwin-Song-Book](/images/examples/longest.png)\n\n(It runs into [Spotify's API limitation](https://developer.spotify.com/documentation/web-api/reference/albums/get-albums-tracks \"Spotify's API - Get an albums' tracks\") so it only gets 50 of the 59 songs but for lols)\n\n\n\n# Known Bugs\n‚Ä¢ Single track albums (Singles) - I know they don't work at all and throw an error. Not sure how to fix this other than with an exception. WIP (there are not a lot of them so not worried, but for example [?](https://open.spotify.com/album/1P5VJYlvS4OrUAdzxP82kG?si=Ee2XoEnbQxCPYZzCiJVTvw) with URI 1P5VJYlvS4OrUAdzxP82kG is an album with only one track)\n\n","source":"_posts/Spotify-analyzer.md","raw":"---\ntitle: Spotify-analyzer\ndate: 2021-03-26 20:43:42\ntags:\n---\n# Spotify-analyzer\n This is a program that analyzes entire albums with [Spotify's stats](https://developer.spotify.com/documentation/web-api/reference/tracks/get-several-audio-features/).\n\nThis is an example of the [900](https://open.spotify.com/album/3yj1EziuVuch1OayyM95az?si=Z6Uzb4IXTl6ld2-9Ti2ubA) album. It shows the best song in each category in the subplot title and a legend at the bottom.\n![900](/images/examples/900.png)\n\n\n# Roadmap\n‚Ä¢ Make it get the album if you enter an individual song\n\n‚Ä¢ Usable for playlists and singles\n\n‚Ä¢ Make it compare in between albums\n\n‚Ä¢ Get conclusions in between albums\n\n‚Ä¢ Get popularity numbers and cross them with the audio features\n\n    ‚Ä¢ Get it to next level ideas:\n\n     ‚Ä¢ Get this into a backend and do it in a web server\n\n     ‚Ä¢ Make it public to use\n\n# More examples\n\nFor a large album, [Madam X](https://open.spotify.com/album/1G2YEQPXaOj1JZwa3ZiGe8?si=YA4YSD9MR6SlNerjUM2gcQ):\n![Madam-X](/images/examples/madam-x.png)\n\n\nFor the longest album I could find, [Ella Fitzgerald Sings The George And Ira Gershwin Song Book](https://open.spotify.com/album/2vz9bOelnO5EoDBPkzEJjt?si=6xp-6ifPQGusfzhjRA8o7g):\n\n![Ella-Fitzgerald-Sings-The-George-And-Ira-Gershwin-Song-Book](/images/examples/longest.png)\n\n(It runs into [Spotify's API limitation](https://developer.spotify.com/documentation/web-api/reference/albums/get-albums-tracks \"Spotify's API - Get an albums' tracks\") so it only gets 50 of the 59 songs but for lols)\n\n\n\n# Known Bugs\n‚Ä¢ Single track albums (Singles) - I know they don't work at all and throw an error. Not sure how to fix this other than with an exception. WIP (there are not a lot of them so not worried, but for example [?](https://open.spotify.com/album/1P5VJYlvS4OrUAdzxP82kG?si=Ee2XoEnbQxCPYZzCiJVTvw) with URI 1P5VJYlvS4OrUAdzxP82kG is an album with only one track)\n\n","slug":"Spotify-analyzer","published":1,"updated":"2025-09-25T19:43:00.523Z","comments":1,"layout":"post","photos":[],"_id":"cuidZx2aA5HbqsH6sKylSdIAd","content":"<h1 id=\"Spotify-analyzer\"><a href=\"#Spotify-analyzer\" class=\"headerlink\" title=\"Spotify-analyzer\"></a>Spotify-analyzer</h1><p> This is a program that analyzes entire albums with <a href=\"https://developer.spotify.com/documentation/web-api/reference/tracks/get-several-audio-features/\">Spotify‚Äôs stats</a>.</p>\n<p>This is an example of the <a href=\"https://open.spotify.com/album/3yj1EziuVuch1OayyM95az?si=Z6Uzb4IXTl6ld2-9Ti2ubA\">900</a> album. It shows the best song in each category in the subplot title and a legend at the bottom.<br><img src=\"/images/examples/900.png\" alt=\"900\"></p>\n<h1 id=\"Roadmap\"><a href=\"#Roadmap\" class=\"headerlink\" title=\"Roadmap\"></a>Roadmap</h1><p>‚Ä¢ Make it get the album if you enter an individual song</p>\n<p>‚Ä¢ Usable for playlists and singles</p>\n<p>‚Ä¢ Make it compare in between albums</p>\n<p>‚Ä¢ Get conclusions in between albums</p>\n<p>‚Ä¢ Get popularity numbers and cross them with the audio features</p>\n<pre><code>‚Ä¢ Get it to next level ideas:\n\n ‚Ä¢ Get this into a backend and do it in a web server\n\n ‚Ä¢ Make it public to use\n</code></pre>\n<h1 id=\"More-examples\"><a href=\"#More-examples\" class=\"headerlink\" title=\"More examples\"></a>More examples</h1><p>For a large album, <a href=\"https://open.spotify.com/album/1G2YEQPXaOj1JZwa3ZiGe8?si=YA4YSD9MR6SlNerjUM2gcQ\">Madam X</a>:<br><img src=\"/images/examples/madam-x.png\" alt=\"Madam-X\"></p>\n<p>For the longest album I could find, <a href=\"https://open.spotify.com/album/2vz9bOelnO5EoDBPkzEJjt?si=6xp-6ifPQGusfzhjRA8o7g\">Ella Fitzgerald Sings The George And Ira Gershwin Song Book</a>:</p>\n<p><img src=\"/images/examples/longest.png\" alt=\"Ella-Fitzgerald-Sings-The-George-And-Ira-Gershwin-Song-Book\"></p>\n<p>(It runs into <a href=\"https://developer.spotify.com/documentation/web-api/reference/albums/get-albums-tracks\" title=\"Spotify&#39;s API - Get an albums&#39; tracks\">Spotify‚Äôs API limitation</a> so it only gets 50 of the 59 songs but for lols)</p>\n<h1 id=\"Known-Bugs\"><a href=\"#Known-Bugs\" class=\"headerlink\" title=\"Known Bugs\"></a>Known Bugs</h1><p>‚Ä¢ Single track albums (Singles) - I know they don‚Äôt work at all and throw an error. Not sure how to fix this other than with an exception. WIP (there are not a lot of them so not worried, but for example <a href=\"https://open.spotify.com/album/1P5VJYlvS4OrUAdzxP82kG?si=Ee2XoEnbQxCPYZzCiJVTvw\">?</a> with URI 1P5VJYlvS4OrUAdzxP82kG is an album with only one track)</p>\n","excerpt":"","more":"<h1 id=\"Spotify-analyzer\"><a href=\"#Spotify-analyzer\" class=\"headerlink\" title=\"Spotify-analyzer\"></a>Spotify-analyzer</h1><p> This is a program that analyzes entire albums with <a href=\"https://developer.spotify.com/documentation/web-api/reference/tracks/get-several-audio-features/\">Spotify‚Äôs stats</a>.</p>\n<p>This is an example of the <a href=\"https://open.spotify.com/album/3yj1EziuVuch1OayyM95az?si=Z6Uzb4IXTl6ld2-9Ti2ubA\">900</a> album. It shows the best song in each category in the subplot title and a legend at the bottom.<br><img src=\"/images/examples/900.png\" alt=\"900\"></p>\n<h1 id=\"Roadmap\"><a href=\"#Roadmap\" class=\"headerlink\" title=\"Roadmap\"></a>Roadmap</h1><p>‚Ä¢ Make it get the album if you enter an individual song</p>\n<p>‚Ä¢ Usable for playlists and singles</p>\n<p>‚Ä¢ Make it compare in between albums</p>\n<p>‚Ä¢ Get conclusions in between albums</p>\n<p>‚Ä¢ Get popularity numbers and cross them with the audio features</p>\n<pre><code>‚Ä¢ Get it to next level ideas:\n\n ‚Ä¢ Get this into a backend and do it in a web server\n\n ‚Ä¢ Make it public to use\n</code></pre>\n<h1 id=\"More-examples\"><a href=\"#More-examples\" class=\"headerlink\" title=\"More examples\"></a>More examples</h1><p>For a large album, <a href=\"https://open.spotify.com/album/1G2YEQPXaOj1JZwa3ZiGe8?si=YA4YSD9MR6SlNerjUM2gcQ\">Madam X</a>:<br><img src=\"/images/examples/madam-x.png\" alt=\"Madam-X\"></p>\n<p>For the longest album I could find, <a href=\"https://open.spotify.com/album/2vz9bOelnO5EoDBPkzEJjt?si=6xp-6ifPQGusfzhjRA8o7g\">Ella Fitzgerald Sings The George And Ira Gershwin Song Book</a>:</p>\n<p><img src=\"/images/examples/longest.png\" alt=\"Ella-Fitzgerald-Sings-The-George-And-Ira-Gershwin-Song-Book\"></p>\n<p>(It runs into <a href=\"https://developer.spotify.com/documentation/web-api/reference/albums/get-albums-tracks\" title=\"Spotify&#39;s API - Get an albums&#39; tracks\">Spotify‚Äôs API limitation</a> so it only gets 50 of the 59 songs but for lols)</p>\n<h1 id=\"Known-Bugs\"><a href=\"#Known-Bugs\" class=\"headerlink\" title=\"Known Bugs\"></a>Known Bugs</h1><p>‚Ä¢ Single track albums (Singles) - I know they don‚Äôt work at all and throw an error. Not sure how to fix this other than with an exception. WIP (there are not a lot of them so not worried, but for example <a href=\"https://open.spotify.com/album/1P5VJYlvS4OrUAdzxP82kG?si=Ee2XoEnbQxCPYZzCiJVTvw\">?</a> with URI 1P5VJYlvS4OrUAdzxP82kG is an album with only one track)</p>\n"},{"title":"Utility-Chrome-Extension","date":"2020-02-13T01:23:19.000Z","_content":"\nPersonal utilities for chrome.\nFor now, this extension only counts words and characters in a given text. \nMy intent is to extend the functionality and include more things like color catcher or screenshots functionality.\n\nThis is how it looks now:\n\n![demo](/images/demo.png)\n\nYou can check the code in my github [here](https://github.com/Aureliusf/Utility-Chrome-Extension)\n\n","source":"_posts/Utility-Chrome-Extension.md","raw":"---\ntitle: Utility-Chrome-Extension\ndate: 2020-02-12 20:23:19\ntags:\n---\n\nPersonal utilities for chrome.\nFor now, this extension only counts words and characters in a given text. \nMy intent is to extend the functionality and include more things like color catcher or screenshots functionality.\n\nThis is how it looks now:\n\n![demo](/images/demo.png)\n\nYou can check the code in my github [here](https://github.com/Aureliusf/Utility-Chrome-Extension)\n\n","slug":"Utility-Chrome-Extension","published":1,"updated":"2025-09-25T19:43:00.523Z","comments":1,"layout":"post","photos":[],"_id":"cuidFAyoJxFxZpTg7XacLTz51","content":"<p>Personal utilities for chrome.<br>For now, this extension only counts words and characters in a given text.<br>My intent is to extend the functionality and include more things like color catcher or screenshots functionality.</p>\n<p>This is how it looks now:</p>\n<p><img src=\"/images/demo.png\" alt=\"demo\"></p>\n<p>You can check the code in my github <a href=\"https://github.com/Aureliusf/Utility-Chrome-Extension\">here</a></p>\n","excerpt":"","more":"<p>Personal utilities for chrome.<br>For now, this extension only counts words and characters in a given text.<br>My intent is to extend the functionality and include more things like color catcher or screenshots functionality.</p>\n<p>This is how it looks now:</p>\n<p><img src=\"/images/demo.png\" alt=\"demo\"></p>\n<p>You can check the code in my github <a href=\"https://github.com/Aureliusf/Utility-Chrome-Extension\">here</a></p>\n"},{"title":"bo.tf","date":"2020-01-02T04:17:07.000Z","_content":"bo.tf is a url shortener that I made back in 2018 as a weekend project.\n\nAfter looking for ready to ship projects I found [YOURLS](https://yourls.org) it is a light-weight open-source url shortener made in php and with a lot of customizability. It also has great features, such as link stats, automatic filtering or bulk creation of short links. But it has a big problems, it looks straight up from 2006.\nLuckily it has plugins and after some diging I got to [Sleeky](https://sleeky.flynntes.com) theme, this looks wayy better.\n\nWith some extra diging in configs and some additions such as Google Analytics, I got up and runnign with [bo.tf](http://bo.tf)\n\nRight now almost two years later still has dozens of users each month and I've been able to keep up with spam and other malicious intents.\n\n","source":"_posts/bo-tf.md","raw":"---\ntitle: bo.tf\ndate: 2020-01-01 23:17:07\ntags:\n---\nbo.tf is a url shortener that I made back in 2018 as a weekend project.\n\nAfter looking for ready to ship projects I found [YOURLS](https://yourls.org) it is a light-weight open-source url shortener made in php and with a lot of customizability. It also has great features, such as link stats, automatic filtering or bulk creation of short links. But it has a big problems, it looks straight up from 2006.\nLuckily it has plugins and after some diging I got to [Sleeky](https://sleeky.flynntes.com) theme, this looks wayy better.\n\nWith some extra diging in configs and some additions such as Google Analytics, I got up and runnign with [bo.tf](http://bo.tf)\n\nRight now almost two years later still has dozens of users each month and I've been able to keep up with spam and other malicious intents.\n\n","slug":"bo-tf","published":1,"updated":"2025-09-25T19:43:00.523Z","comments":1,"layout":"post","photos":[],"_id":"cuidaAur7AS94ZrkUy_cTtKBU","content":"<p>bo.tf is a url shortener that I made back in 2018 as a weekend project.</p>\n<p>After looking for ready to ship projects I found <a href=\"https://yourls.org/\">YOURLS</a> it is a light-weight open-source url shortener made in php and with a lot of customizability. It also has great features, such as link stats, automatic filtering or bulk creation of short links. But it has a big problems, it looks straight up from 2006.<br>Luckily it has plugins and after some diging I got to <a href=\"https://sleeky.flynntes.com/\">Sleeky</a> theme, this looks wayy better.</p>\n<p>With some extra diging in configs and some additions such as Google Analytics, I got up and runnign with <a href=\"http://bo.tf/\">bo.tf</a></p>\n<p>Right now almost two years later still has dozens of users each month and I‚Äôve been able to keep up with spam and other malicious intents.</p>\n","excerpt":"","more":"<p>bo.tf is a url shortener that I made back in 2018 as a weekend project.</p>\n<p>After looking for ready to ship projects I found <a href=\"https://yourls.org/\">YOURLS</a> it is a light-weight open-source url shortener made in php and with a lot of customizability. It also has great features, such as link stats, automatic filtering or bulk creation of short links. But it has a big problems, it looks straight up from 2006.<br>Luckily it has plugins and after some diging I got to <a href=\"https://sleeky.flynntes.com/\">Sleeky</a> theme, this looks wayy better.</p>\n<p>With some extra diging in configs and some additions such as Google Analytics, I got up and runnign with <a href=\"http://bo.tf/\">bo.tf</a></p>\n<p>Right now almost two years later still has dozens of users each month and I‚Äôve been able to keep up with spam and other malicious intents.</p>\n"},{"title":"Serve n8n publicly with nixOS","date":"2025-06-25T19:59:22.000Z","_content":"\n# Serve n8n with nixOS\n\nI have seen nix and nixOS all over the internet and see how people swear by it and the rock solid deployments it can offer. \n\nWhen I wanted to look deeper into n8n I took the opportunity to do both things at the same time, learn n8n and nix.\n\n# n8n\n\nn8n is a \"Fair-code workflow automation platform with native AI capabilities\". [n8n-io/n8n](https://github.com/n8n-io/n8n) \nMy tldr; better interface for zapier that my father can finally use and ü™Ñ AI ü™Ñ\n\nn8n can be run with docker and more recently with npx directly. \nRegretfully, I did not get the memo in time and started this project with docker instead before npx was a viable option. \n\nnixOS is attractive due to the whole system being declarable on the configuration. And if there is things you want to leave non declarative, you can do so no problem!\n\nBecause the system is meant to be declarative and dependencies are separately stored. You can even use different versions of packages on the same system without interfering. Due to this new found capability with nixOS, the nix way to run services is not with a virtualization layer but directly on bare metal.\n\nTBD will transfer from docker to running directly with npx. \n\nTo have run the container, it pretty much worked right away. n8n needs SSL certificates to work properly, other than that I used the docker compose on the docs changing a couple details and importing the DB secrets from an .env file\n# nixOS\n\n[nixOS](https://nixos.wiki/) is a Linux distribution based on the nix package manager that uses an immutable design and an atomic update model. \nIts use of a declarative configuration system allows reproducibility, portability and a light server.\n\nAfter grabbing the GUI installer to start familiarizing with the new distro I set up ssh keys and sshd service in the n8n-server machine to start treating it like a real server.\n\nThis is what I did to ensure ssh would be available every time the system boots and the right public keys are authorized.\nFurthermore and to be better safe than sorry, fail2ban with some whitelisted local IPs.\n```` nix\n  # SSH configs\n  programs.ssh.startAgent = true;\n\n  # Add github and public facing server keys every time\n\n  users.users.server.openssh.authorizedKeys.keys = [\n    \"/home/server/.ssh/github.pub\"\n    \"/home/server/.ssh/vultr.pub\"\n  ];\n\n  # Enable the OpenSSH daemon.\n  services.openssh = {\n    enable = true;\n    settings = {\n      PasswordAuthentication = false; # only key pairs üîë\n      PrintMotd = true;\n    };\n  };\n\n  services.fail2ban = {\n    enable = true;\n    maxretry = 3;\n    bantime-increment.enable = true;\n    ignoreIP = [\n      \"127.0.0.1/8\" # local machine traffic\n      \"10.0.0.174\" # local network traffic\n      \"100.67.201.23\" # local tailscale traffic\n    ];\n  };\n````\n\nIn order to have access to n8n-server even when not at home and in line with the rest of my homelab, tailscale\n```` nix\n  # Enable Tailscale\n  services.tailscale.enable = true;\n\n  # Networking\n  # Enable SSH access in from Tailscale network 22\n  # Enable http/s traffic to go through 80 and 443 for access n8n thorugh tailscale\n  networking.firewall = {\n    enable = true;\n    trustedInterfaces = [\"tailscale0\"];\n    allowedUDPPorts = [config.services.tailscale.port];\n    allowedTCPPorts = [22 443 80];\n  };\n\n`````\n\nOne of the first big issues I faced was loosing my old configuration after I made breaking changes while trying to properly set up docker.\nnixOS will *always* have a working build, that is true and extremely useful. If you run nixOS, you will never have a broken system, period.\nBUT if you loose your old `configuration.nix` because of a change not tracked properly, you have lost it.\n\nTo fix this, you can set up nixOS to copy your config files to the appropriate system generation directory.\n````nix\n  # Copy the NixOS configuration file and link it from the resulting system\n  # (/run/current-system/configuration.nix). This is useful in case you accidentally delete configuration.nix.\n  system.copySystemConfiguration = true;\n`````\nThis setting works even in more complex multi-file configuration system like in my regular dotfiles.\n\n# Serve\nThe easiest and safest way I found to serve a locally hosted service through a public domain that can get Let's Encrypt SSL certificates is with an ssh tunnel.\nI started using Serveo with worked great BUT it would disconnect at once a day even when using autossh. For that I had to move into hosting my own public facing server.\nI chose to use Vultr with the cheapest possible VPS. It runs nginx in an AlmaLinux system.\n\nThis is the flow for a given user:\n```mermaid\ngraph TD\n    A[Client Browser] -->|HTTP/S Request| B(base.org.es)\n    B -->|\"DNS Resolution (Vultr)\"| C[Vultr Instance]\n    C -->|\"Nginx\"| D{\"Vultr Internal Port 7575\"}\n    D -->|\"SSH Tunnel (Vultr Side)\"| E((SSH Tunnel))\n    E -->|\"SSH Tunnel (Local Side)\"| F[Local nixOS n8n-server]\n    F -->|\"Local Port Forwarding\"| G(n8n container)\n\n    subgraph Vultr Infrastructure\n        C\n        D\n    end\n\n    subgraph Local Infrastructure\n        F\n        G\n    end\n\n    %% Flow Explanations\n    click A \"User's browser initiates request\"\n    click B \"Domain resolves to Vultr IP via DNS\"\n    click C \"Nginx on Vultr instance receives request\"\n    click D \"Nginx reverse proxies to internal Vultr port 7575\"\n    click E \"SSH tunnel securely forwards traffic from Vultr port 7575 to your local machine\"\n    click F \"Local machine receives forwarded traffic from SSH tunnel\"\n    click G \"n8n server receives traffic on its local port\"\n\n```\nThis way I don't need to open any ports in my local network and open my homelab this way. With this ssh tunnel, traffic should only be able to access what is served on the local port is pointed to and nothing else. \n\nThis means that I am unable to ssh into my n8n-server through base.org.es at all even though sshd is running, even from one of the whitelisted IPs.\n","source":"_posts/nixOS.md","raw":"---\ntitle: Serve n8n publicly with nixOS\ndate: 2025-06-25 15:59:22\ntags:\n---\n\n# Serve n8n with nixOS\n\nI have seen nix and nixOS all over the internet and see how people swear by it and the rock solid deployments it can offer. \n\nWhen I wanted to look deeper into n8n I took the opportunity to do both things at the same time, learn n8n and nix.\n\n# n8n\n\nn8n is a \"Fair-code workflow automation platform with native AI capabilities\". [n8n-io/n8n](https://github.com/n8n-io/n8n) \nMy tldr; better interface for zapier that my father can finally use and ü™Ñ AI ü™Ñ\n\nn8n can be run with docker and more recently with npx directly. \nRegretfully, I did not get the memo in time and started this project with docker instead before npx was a viable option. \n\nnixOS is attractive due to the whole system being declarable on the configuration. And if there is things you want to leave non declarative, you can do so no problem!\n\nBecause the system is meant to be declarative and dependencies are separately stored. You can even use different versions of packages on the same system without interfering. Due to this new found capability with nixOS, the nix way to run services is not with a virtualization layer but directly on bare metal.\n\nTBD will transfer from docker to running directly with npx. \n\nTo have run the container, it pretty much worked right away. n8n needs SSL certificates to work properly, other than that I used the docker compose on the docs changing a couple details and importing the DB secrets from an .env file\n# nixOS\n\n[nixOS](https://nixos.wiki/) is a Linux distribution based on the nix package manager that uses an immutable design and an atomic update model. \nIts use of a declarative configuration system allows reproducibility, portability and a light server.\n\nAfter grabbing the GUI installer to start familiarizing with the new distro I set up ssh keys and sshd service in the n8n-server machine to start treating it like a real server.\n\nThis is what I did to ensure ssh would be available every time the system boots and the right public keys are authorized.\nFurthermore and to be better safe than sorry, fail2ban with some whitelisted local IPs.\n```` nix\n  # SSH configs\n  programs.ssh.startAgent = true;\n\n  # Add github and public facing server keys every time\n\n  users.users.server.openssh.authorizedKeys.keys = [\n    \"/home/server/.ssh/github.pub\"\n    \"/home/server/.ssh/vultr.pub\"\n  ];\n\n  # Enable the OpenSSH daemon.\n  services.openssh = {\n    enable = true;\n    settings = {\n      PasswordAuthentication = false; # only key pairs üîë\n      PrintMotd = true;\n    };\n  };\n\n  services.fail2ban = {\n    enable = true;\n    maxretry = 3;\n    bantime-increment.enable = true;\n    ignoreIP = [\n      \"127.0.0.1/8\" # local machine traffic\n      \"10.0.0.174\" # local network traffic\n      \"100.67.201.23\" # local tailscale traffic\n    ];\n  };\n````\n\nIn order to have access to n8n-server even when not at home and in line with the rest of my homelab, tailscale\n```` nix\n  # Enable Tailscale\n  services.tailscale.enable = true;\n\n  # Networking\n  # Enable SSH access in from Tailscale network 22\n  # Enable http/s traffic to go through 80 and 443 for access n8n thorugh tailscale\n  networking.firewall = {\n    enable = true;\n    trustedInterfaces = [\"tailscale0\"];\n    allowedUDPPorts = [config.services.tailscale.port];\n    allowedTCPPorts = [22 443 80];\n  };\n\n`````\n\nOne of the first big issues I faced was loosing my old configuration after I made breaking changes while trying to properly set up docker.\nnixOS will *always* have a working build, that is true and extremely useful. If you run nixOS, you will never have a broken system, period.\nBUT if you loose your old `configuration.nix` because of a change not tracked properly, you have lost it.\n\nTo fix this, you can set up nixOS to copy your config files to the appropriate system generation directory.\n````nix\n  # Copy the NixOS configuration file and link it from the resulting system\n  # (/run/current-system/configuration.nix). This is useful in case you accidentally delete configuration.nix.\n  system.copySystemConfiguration = true;\n`````\nThis setting works even in more complex multi-file configuration system like in my regular dotfiles.\n\n# Serve\nThe easiest and safest way I found to serve a locally hosted service through a public domain that can get Let's Encrypt SSL certificates is with an ssh tunnel.\nI started using Serveo with worked great BUT it would disconnect at once a day even when using autossh. For that I had to move into hosting my own public facing server.\nI chose to use Vultr with the cheapest possible VPS. It runs nginx in an AlmaLinux system.\n\nThis is the flow for a given user:\n```mermaid\ngraph TD\n    A[Client Browser] -->|HTTP/S Request| B(base.org.es)\n    B -->|\"DNS Resolution (Vultr)\"| C[Vultr Instance]\n    C -->|\"Nginx\"| D{\"Vultr Internal Port 7575\"}\n    D -->|\"SSH Tunnel (Vultr Side)\"| E((SSH Tunnel))\n    E -->|\"SSH Tunnel (Local Side)\"| F[Local nixOS n8n-server]\n    F -->|\"Local Port Forwarding\"| G(n8n container)\n\n    subgraph Vultr Infrastructure\n        C\n        D\n    end\n\n    subgraph Local Infrastructure\n        F\n        G\n    end\n\n    %% Flow Explanations\n    click A \"User's browser initiates request\"\n    click B \"Domain resolves to Vultr IP via DNS\"\n    click C \"Nginx on Vultr instance receives request\"\n    click D \"Nginx reverse proxies to internal Vultr port 7575\"\n    click E \"SSH tunnel securely forwards traffic from Vultr port 7575 to your local machine\"\n    click F \"Local machine receives forwarded traffic from SSH tunnel\"\n    click G \"n8n server receives traffic on its local port\"\n\n```\nThis way I don't need to open any ports in my local network and open my homelab this way. With this ssh tunnel, traffic should only be able to access what is served on the local port is pointed to and nothing else. \n\nThis means that I am unable to ssh into my n8n-server through base.org.es at all even though sshd is running, even from one of the whitelisted IPs.\n","slug":"nixOS","published":1,"updated":"2025-11-03T04:07:52.762Z","_id":"cuidVN5Hok2PDIJ9k1wedRFPW","comments":1,"layout":"post","photos":[],"content":"<h1 id=\"Serve-n8n-with-nixOS\"><a href=\"#Serve-n8n-with-nixOS\" class=\"headerlink\" title=\"Serve n8n with nixOS\"></a>Serve n8n with nixOS</h1><p>I have seen nix and nixOS all over the internet and see how people swear by it and the rock solid deployments it can offer. </p>\n<p>When I wanted to look deeper into n8n I took the opportunity to do both things at the same time, learn n8n and nix.</p>\n<h1 id=\"n8n\"><a href=\"#n8n\" class=\"headerlink\" title=\"n8n\"></a>n8n</h1><p>n8n is a ‚ÄúFair-code workflow automation platform with native AI capabilities‚Äù. <a href=\"https://github.com/n8n-io/n8n\">n8n-io&#x2F;n8n</a><br>My tldr; better interface for zapier that my father can finally use and ü™Ñ AI ü™Ñ</p>\n<p>n8n can be run with docker and more recently with npx directly.<br>Regretfully, I did not get the memo in time and started this project with docker instead before npx was a viable option. </p>\n<p>nixOS is attractive due to the whole system being declarable on the configuration. And if there is things you want to leave non declarative, you can do so no problem!</p>\n<p>Because the system is meant to be declarative and dependencies are separately stored. You can even use different versions of packages on the same system without interfering. Due to this new found capability with nixOS, the nix way to run services is not with a virtualization layer but directly on bare metal.</p>\n<p>TBD will transfer from docker to running directly with npx. </p>\n<p>To have run the container, it pretty much worked right away. n8n needs SSL certificates to work properly, other than that I used the docker compose on the docs changing a couple details and importing the DB secrets from an .env file</p>\n<h1 id=\"nixOS\"><a href=\"#nixOS\" class=\"headerlink\" title=\"nixOS\"></a>nixOS</h1><p><a href=\"https://nixos.wiki/\">nixOS</a> is a Linux distribution based on the nix package manager that uses an immutable design and an atomic update model.<br>Its use of a declarative configuration system allows reproducibility, portability and a light server.</p>\n<p>After grabbing the GUI installer to start familiarizing with the new distro I set up ssh keys and sshd service in the n8n-server machine to start treating it like a real server.</p>\n<p>This is what I did to ensure ssh would be available every time the system boots and the right public keys are authorized.<br>Furthermore and to be better safe than sorry, fail2ban with some whitelisted local IPs.</p>\n<pre><code class=\"highlight nix\"><span class=\"comment\"># SSH configs</span>\np<span class=\"attr\">rograms.ssh.startAgent</span> <span class=\"operator\">=</span> <span class=\"literal\">true</span>;\n\n<span class=\"comment\"># Add github and public facing server keys every time</span>\n\n<span class=\"attr\">users.users.server.openssh.authorizedKeys.keys</span> <span class=\"operator\">=</span> [\n  <span class=\"string\">&quot;/home/server/.ssh/github.pub&quot;</span>\n  <span class=\"string\">&quot;/home/server/.ssh/vultr.pub&quot;</span>\n];\n\n<span class=\"comment\"># Enable the OpenSSH daemon.</span>\ns<span class=\"attr\">ervices.openssh</span> <span class=\"operator\">=</span> &#123;\n  <span class=\"attr\">enable</span> <span class=\"operator\">=</span> <span class=\"literal\">true</span>;\n  <span class=\"attr\">settings</span> <span class=\"operator\">=</span> &#123;\n    <span class=\"attr\">PasswordAuthentication</span> <span class=\"operator\">=</span> <span class=\"literal\">false</span>; <span class=\"comment\"># only key pairs üîë</span>\n    <span class=\"attr\">PrintMotd</span> <span class=\"operator\">=</span> <span class=\"literal\">true</span>;\n  &#125;;\n&#125;;\n\n<span class=\"attr\">services.fail2ban</span> <span class=\"operator\">=</span> &#123;\n  <span class=\"attr\">enable</span> <span class=\"operator\">=</span> <span class=\"literal\">true</span>;\n  <span class=\"attr\">maxretry</span> <span class=\"operator\">=</span> <span class=\"number\">3</span>;\n  <span class=\"attr\">bantime-increment.enable</span> <span class=\"operator\">=</span> <span class=\"literal\">true</span>;\n  <span class=\"attr\">ignoreIP</span> <span class=\"operator\">=</span> [\n    <span class=\"string\">&quot;127.0.0.1/8&quot;</span> <span class=\"comment\"># local machine traffic</span>\n    <span class=\"string\">&quot;10.0.0.174&quot;</span> <span class=\"comment\"># local network traffic</span>\n    <span class=\"string\">&quot;100.67.201.23&quot;</span> <span class=\"comment\"># local tailscale traffic</span>\n  ];\n&#125;;</code></pre>\n\n<p>In order to have access to n8n-server even when not at home and in line with the rest of my homelab, tailscale</p>\n<pre><div class=\"caption\"><span>nix</span></div><code class=\"highlight `\">  # Enable Tailscale\n  services.tailscale.enable = true;\n\n  # Networking\n  # Enable SSH access in from Tailscale network 22\n  # Enable http/s traffic to go through 80 and 443 for access n8n thorugh tailscale\n  networking.firewall = &#123;\n    enable = true;\n    trustedInterfaces = [&quot;tailscale0&quot;];\n    allowedUDPPorts = [config.services.tailscale.port];\n    allowedTCPPorts = [22 443 80];\n  &#125;;\n\n`````\n\nOne of the first big issues I faced was loosing my old configuration after I made breaking changes while trying to properly set up docker.\nnixOS will *always* have a working build, that is true and extremely useful. If you run nixOS, you will never have a broken system, period.\nBUT if you loose your old `configuration.nix` because of a change not tracked properly, you have lost it.\n\nTo fix this, you can set up nixOS to copy your config files to the appropriate system generation directory.\n````nix\n  # Copy the NixOS configuration file and link it from the resulting system\n  # (/run/current-system/configuration.nix). This is useful in case you accidentally delete configuration.nix.\n  system.copySystemConfiguration = true;\n`````\nThis setting works even in more complex multi-file configuration system like in my regular dotfiles.\n\n# Serve\nThe easiest and safest way I found to serve a locally hosted service through a public domain that can get Let&#x27;s Encrypt SSL certificates is with an ssh tunnel.\nI started using Serveo with worked great BUT it would disconnect at once a day even when using autossh. For that I had to move into hosting my own public facing server.\nI chose to use Vultr with the cheapest possible VPS. It runs nginx in an AlmaLinux system.\n\nThis is the flow for a given user:\n```mermaid\ngraph TD\n    A[Client Browser] --&gt;|HTTP/S Request| B(base.org.es)\n    B --&gt;|&quot;DNS Resolution (Vultr)&quot;| C[Vultr Instance]\n    C --&gt;|&quot;Nginx&quot;| D&#123;&quot;Vultr Internal Port 7575&quot;&#125;\n    D --&gt;|&quot;SSH Tunnel (Vultr Side)&quot;| E((SSH Tunnel))\n    E --&gt;|&quot;SSH Tunnel (Local Side)&quot;| F[Local nixOS n8n-server]\n    F --&gt;|&quot;Local Port Forwarding&quot;| G(n8n container)\n\n    subgraph Vultr Infrastructure\n        C\n        D\n    end\n\n    subgraph Local Infrastructure\n        F\n        G\n    end\n\n    %% Flow Explanations\n    click A &quot;User&#x27;s browser initiates request&quot;\n    click B &quot;Domain resolves to Vultr IP via DNS&quot;\n    click C &quot;Nginx on Vultr instance receives request&quot;\n    click D &quot;Nginx reverse proxies to internal Vultr port 7575&quot;\n    click E &quot;SSH tunnel securely forwards traffic from Vultr port 7575 to your local machine&quot;\n    click F &quot;Local machine receives forwarded traffic from SSH tunnel&quot;\n    click G &quot;n8n server receives traffic on its local port&quot;\n</code></pre>\n<p>This way I don‚Äôt need to open any ports in my local network and open my homelab this way. With this ssh tunnel, traffic should only be able to access what is served on the local port is pointed to and nothing else. </p>\n<p>This means that I am unable to ssh into my n8n-server through base.org.es at all even though sshd is running, even from one of the whitelisted IPs.</p>\n","excerpt":"","more":"<h1 id=\"Serve-n8n-with-nixOS\"><a href=\"#Serve-n8n-with-nixOS\" class=\"headerlink\" title=\"Serve n8n with nixOS\"></a>Serve n8n with nixOS</h1><p>I have seen nix and nixOS all over the internet and see how people swear by it and the rock solid deployments it can offer. </p>\n<p>When I wanted to look deeper into n8n I took the opportunity to do both things at the same time, learn n8n and nix.</p>\n<h1 id=\"n8n\"><a href=\"#n8n\" class=\"headerlink\" title=\"n8n\"></a>n8n</h1><p>n8n is a ‚ÄúFair-code workflow automation platform with native AI capabilities‚Äù. <a href=\"https://github.com/n8n-io/n8n\">n8n-io&#x2F;n8n</a><br>My tldr; better interface for zapier that my father can finally use and ü™Ñ AI ü™Ñ</p>\n<p>n8n can be run with docker and more recently with npx directly.<br>Regretfully, I did not get the memo in time and started this project with docker instead before npx was a viable option. </p>\n<p>nixOS is attractive due to the whole system being declarable on the configuration. And if there is things you want to leave non declarative, you can do so no problem!</p>\n<p>Because the system is meant to be declarative and dependencies are separately stored. You can even use different versions of packages on the same system without interfering. Due to this new found capability with nixOS, the nix way to run services is not with a virtualization layer but directly on bare metal.</p>\n<p>TBD will transfer from docker to running directly with npx. </p>\n<p>To have run the container, it pretty much worked right away. n8n needs SSL certificates to work properly, other than that I used the docker compose on the docs changing a couple details and importing the DB secrets from an .env file</p>\n<h1 id=\"nixOS\"><a href=\"#nixOS\" class=\"headerlink\" title=\"nixOS\"></a>nixOS</h1><p><a href=\"https://nixos.wiki/\">nixOS</a> is a Linux distribution based on the nix package manager that uses an immutable design and an atomic update model.<br>Its use of a declarative configuration system allows reproducibility, portability and a light server.</p>\n<p>After grabbing the GUI installer to start familiarizing with the new distro I set up ssh keys and sshd service in the n8n-server machine to start treating it like a real server.</p>\n<p>This is what I did to ensure ssh would be available every time the system boots and the right public keys are authorized.<br>Furthermore and to be better safe than sorry, fail2ban with some whitelisted local IPs.</p>\n<pre><code class=\"highlight nix\"><span class=\"comment\"># SSH configs</span>\np<span class=\"attr\">rograms.ssh.startAgent</span> <span class=\"operator\">=</span> <span class=\"literal\">true</span>;\n\n<span class=\"comment\"># Add github and public facing server keys every time</span>\n\n<span class=\"attr\">users.users.server.openssh.authorizedKeys.keys</span> <span class=\"operator\">=</span> [\n  <span class=\"string\">&quot;/home/server/.ssh/github.pub&quot;</span>\n  <span class=\"string\">&quot;/home/server/.ssh/vultr.pub&quot;</span>\n];\n\n<span class=\"comment\"># Enable the OpenSSH daemon.</span>\ns<span class=\"attr\">ervices.openssh</span> <span class=\"operator\">=</span> &#123;\n  <span class=\"attr\">enable</span> <span class=\"operator\">=</span> <span class=\"literal\">true</span>;\n  <span class=\"attr\">settings</span> <span class=\"operator\">=</span> &#123;\n    <span class=\"attr\">PasswordAuthentication</span> <span class=\"operator\">=</span> <span class=\"literal\">false</span>; <span class=\"comment\"># only key pairs üîë</span>\n    <span class=\"attr\">PrintMotd</span> <span class=\"operator\">=</span> <span class=\"literal\">true</span>;\n  &#125;;\n&#125;;\n\n<span class=\"attr\">services.fail2ban</span> <span class=\"operator\">=</span> &#123;\n  <span class=\"attr\">enable</span> <span class=\"operator\">=</span> <span class=\"literal\">true</span>;\n  <span class=\"attr\">maxretry</span> <span class=\"operator\">=</span> <span class=\"number\">3</span>;\n  <span class=\"attr\">bantime-increment.enable</span> <span class=\"operator\">=</span> <span class=\"literal\">true</span>;\n  <span class=\"attr\">ignoreIP</span> <span class=\"operator\">=</span> [\n    <span class=\"string\">&quot;127.0.0.1/8&quot;</span> <span class=\"comment\"># local machine traffic</span>\n    <span class=\"string\">&quot;10.0.0.174&quot;</span> <span class=\"comment\"># local network traffic</span>\n    <span class=\"string\">&quot;100.67.201.23&quot;</span> <span class=\"comment\"># local tailscale traffic</span>\n  ];\n&#125;;</code></pre>\n\n<p>In order to have access to n8n-server even when not at home and in line with the rest of my homelab, tailscale</p>\n<pre><div class=\"caption\"><span>nix</span></div><code class=\"highlight `\">  # Enable Tailscale\n  services.tailscale.enable = true;\n\n  # Networking\n  # Enable SSH access in from Tailscale network 22\n  # Enable http/s traffic to go through 80 and 443 for access n8n thorugh tailscale\n  networking.firewall = &#123;\n    enable = true;\n    trustedInterfaces = [&quot;tailscale0&quot;];\n    allowedUDPPorts = [config.services.tailscale.port];\n    allowedTCPPorts = [22 443 80];\n  &#125;;\n\n`````\n\nOne of the first big issues I faced was loosing my old configuration after I made breaking changes while trying to properly set up docker.\nnixOS will *always* have a working build, that is true and extremely useful. If you run nixOS, you will never have a broken system, period.\nBUT if you loose your old `configuration.nix` because of a change not tracked properly, you have lost it.\n\nTo fix this, you can set up nixOS to copy your config files to the appropriate system generation directory.\n````nix\n  # Copy the NixOS configuration file and link it from the resulting system\n  # (/run/current-system/configuration.nix). This is useful in case you accidentally delete configuration.nix.\n  system.copySystemConfiguration = true;\n`````\nThis setting works even in more complex multi-file configuration system like in my regular dotfiles.\n\n# Serve\nThe easiest and safest way I found to serve a locally hosted service through a public domain that can get Let&#x27;s Encrypt SSL certificates is with an ssh tunnel.\nI started using Serveo with worked great BUT it would disconnect at once a day even when using autossh. For that I had to move into hosting my own public facing server.\nI chose to use Vultr with the cheapest possible VPS. It runs nginx in an AlmaLinux system.\n\nThis is the flow for a given user:\n```mermaid\ngraph TD\n    A[Client Browser] --&gt;|HTTP/S Request| B(base.org.es)\n    B --&gt;|&quot;DNS Resolution (Vultr)&quot;| C[Vultr Instance]\n    C --&gt;|&quot;Nginx&quot;| D&#123;&quot;Vultr Internal Port 7575&quot;&#125;\n    D --&gt;|&quot;SSH Tunnel (Vultr Side)&quot;| E((SSH Tunnel))\n    E --&gt;|&quot;SSH Tunnel (Local Side)&quot;| F[Local nixOS n8n-server]\n    F --&gt;|&quot;Local Port Forwarding&quot;| G(n8n container)\n\n    subgraph Vultr Infrastructure\n        C\n        D\n    end\n\n    subgraph Local Infrastructure\n        F\n        G\n    end\n\n    %% Flow Explanations\n    click A &quot;User&#x27;s browser initiates request&quot;\n    click B &quot;Domain resolves to Vultr IP via DNS&quot;\n    click C &quot;Nginx on Vultr instance receives request&quot;\n    click D &quot;Nginx reverse proxies to internal Vultr port 7575&quot;\n    click E &quot;SSH tunnel securely forwards traffic from Vultr port 7575 to your local machine&quot;\n    click F &quot;Local machine receives forwarded traffic from SSH tunnel&quot;\n    click G &quot;n8n server receives traffic on its local port&quot;\n</code></pre>\n<p>This way I don‚Äôt need to open any ports in my local network and open my homelab this way. With this ssh tunnel, traffic should only be able to access what is served on the local port is pointed to and nothing else. </p>\n<p>This means that I am unable to ssh into my n8n-server through base.org.es at all even though sshd is running, even from one of the whitelisted IPs.</p>\n"},{"title":"Automated Portfolio: Sanity.io Headless CMS + Astro Frontend + CI/CD on a Global Edge Network","date":"2025-11-10T20:59:22.000Z","_content":"\nThis project is a real-life, high-performing site I built for a Fashion Stylist. For saradm.com, I leveraged the ease of use of Sanity.io headless CMS with the flexibility of Astro as a Frontend to deliver a great user experience for the visitor, the stylist making the content, and for myself maintaining the site. I deployed the site on Cloudflare Pages, utilizing serverless functions for the contact form which I built in TypeScript and integrated with Resend's RESTful API.\n\n## Technical Stack\n\n-   **Frontend Framework:** [Astro](https://astro.build/)\n-   **UI Library:** [React](https://react.dev/) (for interactive components)\n-   **Styling:** [Tailwind CSS](https://tailwindcss.com/)\n-   **Headless CMS:** [Sanity.io](https://www.sanity.io/)\n-   **Deployment & Hosting:** [Cloudflare Pages](https://pages.cloudflare.com/)\n-   **Email Service:** [Resend](https://resend.com/)\n\n## Architectural Highlights & Key Features\n\nI architected this project with the main goal of enabling the end-user (the stylist) to admin the contents, while keeping the site fast, maintainable, and scalable from a development perspective. To achieve this, I used a blend of static site generation and serverless computing.\n\n### 1. Hybrid Architecture with Astro\n\nI built the frontend core of the site with Astro, which I chose for its excellent performance and wide compatibility for different sources. I configured the architecture for server-side rendering to support dynamic API routes while pre-rendering static pages for optimal load times.\nThis hybrid approach provided the best of both worlds: the speed of static sites for content and the flexibility of server-rendered applications for user-interactable pages. Every post gets generated at build time from a queries to the sanity.io CMS.\n\nThe site has two types of pages:\n-   **Static Pages:** Astro statically generates most pages (`index`, `posts`, `[slug]`) at build time, ensuring near-instant delivery from Cloudflare's edge network around the world.\n-   **Dynamic API Routes:** I wrote a serverless API endpoint (`/api/contact.ts`) to handle form submissions without requiring a traditional backend server.\n\n### 2. Headless CMS for Content Management\n\nI used Sanity.io to manage all project content, including text and images. This decouples the content from the presentation layer, allowing the stylist to update their portfolio without needing my intervention, following the JAMstack philosophy. Astro fetches this content at build time to generate the static pages.\n\nHosting all the images in Sanity.io allows me to use Sanity's CDN to serve images at the right size and anywhere in the world.\n\n### 3. Serverless Contact Form\n\nTo handle user inquiries, I implemented a secure and robust contact form:\n\n-   **Frontend:** I used a React component (`ContactForm.jsx`) to provide a modern, interactive user experience with client-side validation. The component manages form state, handles user input, and communicates with the backend API.\n\n-   **Backend:** I wrote an Astro API route that acts as a serverless function deployed on Cloudflare. It receives the form data, validates it, and uses the Resend API to send the email.\n\n-   **Security:** I managed API keys and environment variables securely using Cloudflare's environment variable system, accessing them via `locals.runtime.env` in the Astro backend to prevent exposure on the client-side.\n\n### 4. Responsive Design & Image Optimization\n\nWith users being all around the world and interested in fashion, a major focus for me was creating a visually consistent and responsive experience across all devices.\n\n-   **Tailwind CSS:** I used a utility-first approach for rapid, maintainable styling. I configured custom styles to keep a specific color palette across the whole site in `tailwind.config.js`.\n-   **Responsive Image Loading:** I used the Astro `Image` component to implement `srcset` and `sizes` attributes. This ensures that browsers download the most appropriately sized image based on the device's viewport and resolution, significantly improving performance and reducing bandwidth.\n-   **Dynamic Layouts:** I designed the project gallery with layouts that dynamically adjust based on content, such as aligning text based on the position of the corresponding image and different columns for big screens or mobile.\n\n## Development Process & Problem-Solving\n\nMy development process was iterative, focusing on building features, fixing bugs, and continuous refinement.\n\n-   **Client-Side Interactivity:** A key challenge I faced was implementing a tag-based filtering system on the `/posts` page that worked seamlessly with Astro's view transitions. The initial script I wrote failed on navigation, but I resolved this by leveraging Astro's `astro:page-load` event and the `is:inline` script attribute. This ensured the filter logic re-initialized correctly on each page load.\n\n    ````javascript\n    // src/pages/posts.astro\n    const filterContainer = document.getElementById('tag-filters');\n    const postItems = document.querySelectorAll('.post-item');\n\n    if (filterContainer) {\n      filterContainer.addEventListener('click', (e) => {\n        const target = e.target as HTMLElement;\n        if (target.classList.contains('tag-button')) {\n          // ... code to update active button style ...\n\n          const selectedTag = target.dataset.tag;\n\n          postItems.forEach(item => {\n            const post = item as HTMLElement;\n            const postTags = post.dataset.tags ? post.dataset.tags.split(',') : [];\n            \n            if (selectedTag === 'all' || postTags.includes(String(selectedTag))) {\n              post.style.display = 'block';\n            } else {\n              post.style.display = 'none';\n            }\n          });\n        }\n      });\n    }\n    ````\n\n-   **Build & Rendering:** Early in development, I migrated the project from a purely static output to a server-rendered output (`output: 'server'`) to accommodate the serverless API route for the contact form. I marked specific pages not requiring server-side logic for pre-rendering to maintain performance benefits.\n\nThis project demonstrates my strong understanding of modern web development principles, including JAMstack architecture, performance optimization, and the integration of disparate services (CMS, email) into a cohesive, serverless application.\n","source":"_posts/saradm.com-Fashion-Portfolio-Site.md","raw":"---\ntitle: \"Automated Portfolio: Sanity.io Headless CMS + Astro Frontend + CI/CD on a Global Edge Network\"\ndate: 2025-11-10 15:59:22\ntags:\n---\n\nThis project is a real-life, high-performing site I built for a Fashion Stylist. For saradm.com, I leveraged the ease of use of Sanity.io headless CMS with the flexibility of Astro as a Frontend to deliver a great user experience for the visitor, the stylist making the content, and for myself maintaining the site. I deployed the site on Cloudflare Pages, utilizing serverless functions for the contact form which I built in TypeScript and integrated with Resend's RESTful API.\n\n## Technical Stack\n\n-   **Frontend Framework:** [Astro](https://astro.build/)\n-   **UI Library:** [React](https://react.dev/) (for interactive components)\n-   **Styling:** [Tailwind CSS](https://tailwindcss.com/)\n-   **Headless CMS:** [Sanity.io](https://www.sanity.io/)\n-   **Deployment & Hosting:** [Cloudflare Pages](https://pages.cloudflare.com/)\n-   **Email Service:** [Resend](https://resend.com/)\n\n## Architectural Highlights & Key Features\n\nI architected this project with the main goal of enabling the end-user (the stylist) to admin the contents, while keeping the site fast, maintainable, and scalable from a development perspective. To achieve this, I used a blend of static site generation and serverless computing.\n\n### 1. Hybrid Architecture with Astro\n\nI built the frontend core of the site with Astro, which I chose for its excellent performance and wide compatibility for different sources. I configured the architecture for server-side rendering to support dynamic API routes while pre-rendering static pages for optimal load times.\nThis hybrid approach provided the best of both worlds: the speed of static sites for content and the flexibility of server-rendered applications for user-interactable pages. Every post gets generated at build time from a queries to the sanity.io CMS.\n\nThe site has two types of pages:\n-   **Static Pages:** Astro statically generates most pages (`index`, `posts`, `[slug]`) at build time, ensuring near-instant delivery from Cloudflare's edge network around the world.\n-   **Dynamic API Routes:** I wrote a serverless API endpoint (`/api/contact.ts`) to handle form submissions without requiring a traditional backend server.\n\n### 2. Headless CMS for Content Management\n\nI used Sanity.io to manage all project content, including text and images. This decouples the content from the presentation layer, allowing the stylist to update their portfolio without needing my intervention, following the JAMstack philosophy. Astro fetches this content at build time to generate the static pages.\n\nHosting all the images in Sanity.io allows me to use Sanity's CDN to serve images at the right size and anywhere in the world.\n\n### 3. Serverless Contact Form\n\nTo handle user inquiries, I implemented a secure and robust contact form:\n\n-   **Frontend:** I used a React component (`ContactForm.jsx`) to provide a modern, interactive user experience with client-side validation. The component manages form state, handles user input, and communicates with the backend API.\n\n-   **Backend:** I wrote an Astro API route that acts as a serverless function deployed on Cloudflare. It receives the form data, validates it, and uses the Resend API to send the email.\n\n-   **Security:** I managed API keys and environment variables securely using Cloudflare's environment variable system, accessing them via `locals.runtime.env` in the Astro backend to prevent exposure on the client-side.\n\n### 4. Responsive Design & Image Optimization\n\nWith users being all around the world and interested in fashion, a major focus for me was creating a visually consistent and responsive experience across all devices.\n\n-   **Tailwind CSS:** I used a utility-first approach for rapid, maintainable styling. I configured custom styles to keep a specific color palette across the whole site in `tailwind.config.js`.\n-   **Responsive Image Loading:** I used the Astro `Image` component to implement `srcset` and `sizes` attributes. This ensures that browsers download the most appropriately sized image based on the device's viewport and resolution, significantly improving performance and reducing bandwidth.\n-   **Dynamic Layouts:** I designed the project gallery with layouts that dynamically adjust based on content, such as aligning text based on the position of the corresponding image and different columns for big screens or mobile.\n\n## Development Process & Problem-Solving\n\nMy development process was iterative, focusing on building features, fixing bugs, and continuous refinement.\n\n-   **Client-Side Interactivity:** A key challenge I faced was implementing a tag-based filtering system on the `/posts` page that worked seamlessly with Astro's view transitions. The initial script I wrote failed on navigation, but I resolved this by leveraging Astro's `astro:page-load` event and the `is:inline` script attribute. This ensured the filter logic re-initialized correctly on each page load.\n\n    ````javascript\n    // src/pages/posts.astro\n    const filterContainer = document.getElementById('tag-filters');\n    const postItems = document.querySelectorAll('.post-item');\n\n    if (filterContainer) {\n      filterContainer.addEventListener('click', (e) => {\n        const target = e.target as HTMLElement;\n        if (target.classList.contains('tag-button')) {\n          // ... code to update active button style ...\n\n          const selectedTag = target.dataset.tag;\n\n          postItems.forEach(item => {\n            const post = item as HTMLElement;\n            const postTags = post.dataset.tags ? post.dataset.tags.split(',') : [];\n            \n            if (selectedTag === 'all' || postTags.includes(String(selectedTag))) {\n              post.style.display = 'block';\n            } else {\n              post.style.display = 'none';\n            }\n          });\n        }\n      });\n    }\n    ````\n\n-   **Build & Rendering:** Early in development, I migrated the project from a purely static output to a server-rendered output (`output: 'server'`) to accommodate the serverless API route for the contact form. I marked specific pages not requiring server-side logic for pre-rendering to maintain performance benefits.\n\nThis project demonstrates my strong understanding of modern web development principles, including JAMstack architecture, performance optimization, and the integration of disparate services (CMS, email) into a cohesive, serverless application.\n","slug":"saradm.com-Fashion-Portfolio-Site","published":1,"updated":"2025-11-16T05:38:30.036Z","_id":"cuidZA160wuYywaoNG1zztxh3","comments":1,"layout":"post","photos":[],"content":"<p>This project is a real-life, high-performing site I built for a Fashion Stylist. For saradm.com, I leveraged the ease of use of Sanity.io headless CMS with the flexibility of Astro as a Frontend to deliver a great user experience for the visitor, the stylist making the content, and for myself maintaining the site. I deployed the site on Cloudflare Pages, utilizing serverless functions for the contact form which I built in TypeScript and integrated with Resend‚Äôs RESTful API.</p>\n<h2 id=\"Technical-Stack\"><a href=\"#Technical-Stack\" class=\"headerlink\" title=\"Technical Stack\"></a>Technical Stack</h2><ul>\n<li><strong>Frontend Framework:</strong> <a href=\"https://astro.build/\">Astro</a></li>\n<li><strong>UI Library:</strong> <a href=\"https://react.dev/\">React</a> (for interactive components)</li>\n<li><strong>Styling:</strong> <a href=\"https://tailwindcss.com/\">Tailwind CSS</a></li>\n<li><strong>Headless CMS:</strong> <a href=\"https://www.sanity.io/\">Sanity.io</a></li>\n<li><strong>Deployment &amp; Hosting:</strong> <a href=\"https://pages.cloudflare.com/\">Cloudflare Pages</a></li>\n<li><strong>Email Service:</strong> <a href=\"https://resend.com/\">Resend</a></li>\n</ul>\n<h2 id=\"Architectural-Highlights-Key-Features\"><a href=\"#Architectural-Highlights-Key-Features\" class=\"headerlink\" title=\"Architectural Highlights &amp; Key Features\"></a>Architectural Highlights &amp; Key Features</h2><p>I architected this project with the main goal of enabling the end-user (the stylist) to admin the contents, while keeping the site fast, maintainable, and scalable from a development perspective. To achieve this, I used a blend of static site generation and serverless computing.</p>\n<h3 id=\"1-Hybrid-Architecture-with-Astro\"><a href=\"#1-Hybrid-Architecture-with-Astro\" class=\"headerlink\" title=\"1. Hybrid Architecture with Astro\"></a>1. Hybrid Architecture with Astro</h3><p>I built the frontend core of the site with Astro, which I chose for its excellent performance and wide compatibility for different sources. I configured the architecture for server-side rendering to support dynamic API routes while pre-rendering static pages for optimal load times.<br>This hybrid approach provided the best of both worlds: the speed of static sites for content and the flexibility of server-rendered applications for user-interactable pages. Every post gets generated at build time from a queries to the sanity.io CMS.</p>\n<p>The site has two types of pages:</p>\n<ul>\n<li><strong>Static Pages:</strong> Astro statically generates most pages (<code>index</code>, <code>posts</code>, <code>[slug]</code>) at build time, ensuring near-instant delivery from Cloudflare‚Äôs edge network around the world.</li>\n<li><strong>Dynamic API Routes:</strong> I wrote a serverless API endpoint (<code>/api/contact.ts</code>) to handle form submissions without requiring a traditional backend server.</li>\n</ul>\n<h3 id=\"2-Headless-CMS-for-Content-Management\"><a href=\"#2-Headless-CMS-for-Content-Management\" class=\"headerlink\" title=\"2. Headless CMS for Content Management\"></a>2. Headless CMS for Content Management</h3><p>I used Sanity.io to manage all project content, including text and images. This decouples the content from the presentation layer, allowing the stylist to update their portfolio without needing my intervention, following the JAMstack philosophy. Astro fetches this content at build time to generate the static pages.</p>\n<p>Hosting all the images in Sanity.io allows me to use Sanity‚Äôs CDN to serve images at the right size and anywhere in the world.</p>\n<h3 id=\"3-Serverless-Contact-Form\"><a href=\"#3-Serverless-Contact-Form\" class=\"headerlink\" title=\"3. Serverless Contact Form\"></a>3. Serverless Contact Form</h3><p>To handle user inquiries, I implemented a secure and robust contact form:</p>\n<ul>\n<li><p><strong>Frontend:</strong> I used a React component (<code>ContactForm.jsx</code>) to provide a modern, interactive user experience with client-side validation. The component manages form state, handles user input, and communicates with the backend API.</p>\n</li>\n<li><p><strong>Backend:</strong> I wrote an Astro API route that acts as a serverless function deployed on Cloudflare. It receives the form data, validates it, and uses the Resend API to send the email.</p>\n</li>\n<li><p><strong>Security:</strong> I managed API keys and environment variables securely using Cloudflare‚Äôs environment variable system, accessing them via <code>locals.runtime.env</code> in the Astro backend to prevent exposure on the client-side.</p>\n</li>\n</ul>\n<h3 id=\"4-Responsive-Design-Image-Optimization\"><a href=\"#4-Responsive-Design-Image-Optimization\" class=\"headerlink\" title=\"4. Responsive Design &amp; Image Optimization\"></a>4. Responsive Design &amp; Image Optimization</h3><p>With users being all around the world and interested in fashion, a major focus for me was creating a visually consistent and responsive experience across all devices.</p>\n<ul>\n<li><strong>Tailwind CSS:</strong> I used a utility-first approach for rapid, maintainable styling. I configured custom styles to keep a specific color palette across the whole site in <code>tailwind.config.js</code>.</li>\n<li><strong>Responsive Image Loading:</strong> I used the Astro <code>Image</code> component to implement <code>srcset</code> and <code>sizes</code> attributes. This ensures that browsers download the most appropriately sized image based on the device‚Äôs viewport and resolution, significantly improving performance and reducing bandwidth.</li>\n<li><strong>Dynamic Layouts:</strong> I designed the project gallery with layouts that dynamically adjust based on content, such as aligning text based on the position of the corresponding image and different columns for big screens or mobile.</li>\n</ul>\n<h2 id=\"Development-Process-Problem-Solving\"><a href=\"#Development-Process-Problem-Solving\" class=\"headerlink\" title=\"Development Process &amp; Problem-Solving\"></a>Development Process &amp; Problem-Solving</h2><p>My development process was iterative, focusing on building features, fixing bugs, and continuous refinement.</p>\n<ul>\n<li><p><strong>Client-Side Interactivity:</strong> A key challenge I faced was implementing a tag-based filtering system on the <code>/posts</code> page that worked seamlessly with Astro‚Äôs view transitions. The initial script I wrote failed on navigation, but I resolved this by leveraging Astro‚Äôs <code>astro:page-load</code> event and the <code>is:inline</code> script attribute. This ensured the filter logic re-initialized correctly on each page load.</p>\n<pre><code class=\"highlight javascript\"><span class=\"comment\">// src/pages/posts.astro</span>\n<span class=\"keyword\">const</span> filterContainer = <span class=\"variable language_\">document</span>.<span class=\"title function_\">getElementById</span>(<span class=\"string\">&#x27;tag-filters&#x27;</span>);\n<span class=\"keyword\">const</span> postItems = <span class=\"variable language_\">document</span>.<span class=\"title function_\">querySelectorAll</span>(<span class=\"string\">&#x27;.post-item&#x27;</span>);\n\n<span class=\"keyword\">if</span> (filterContainer) &#123;\n  filterContainer.<span class=\"title function_\">addEventListener</span>(<span class=\"string\">&#x27;click&#x27;</span>, <span class=\"function\">(<span class=\"params\">e</span>) =&gt;</span> &#123;\n    <span class=\"keyword\">const</span> target = e.<span class=\"property\">target</span> <span class=\"keyword\">as</span> <span class=\"title class_\">HTMLElement</span>;\n    <span class=\"keyword\">if</span> (target.<span class=\"property\">classList</span>.<span class=\"title function_\">contains</span>(<span class=\"string\">&#x27;tag-button&#x27;</span>)) &#123;\n      <span class=\"comment\">// ... code to update active button style ...</span>\n\n      <span class=\"keyword\">const</span> selectedTag = target.<span class=\"property\">dataset</span>.<span class=\"property\">tag</span>;\n\n      postItems.<span class=\"title function_\">forEach</span>(<span class=\"function\"><span class=\"params\">item</span> =&gt;</span> &#123;\n        <span class=\"keyword\">const</span> post = item <span class=\"keyword\">as</span> <span class=\"title class_\">HTMLElement</span>;\n        <span class=\"keyword\">const</span> postTags = post.<span class=\"property\">dataset</span>.<span class=\"property\">tags</span> ? post.<span class=\"property\">dataset</span>.<span class=\"property\">tags</span>.<span class=\"title function_\">split</span>(<span class=\"string\">&#x27;,&#x27;</span>) : [];\n        \n        <span class=\"keyword\">if</span> (selectedTag === <span class=\"string\">&#x27;all&#x27;</span> || postTags.<span class=\"title function_\">includes</span>(<span class=\"title class_\">String</span>(selectedTag))) &#123;\n          post.<span class=\"property\">style</span>.<span class=\"property\">display</span> = <span class=\"string\">&#x27;block&#x27;</span>;\n        &#125; <span class=\"keyword\">else</span> &#123;\n          post.<span class=\"property\">style</span>.<span class=\"property\">display</span> = <span class=\"string\">&#x27;none&#x27;</span>;\n        &#125;\n      &#125;);\n    &#125;\n  &#125;);\n&#125;</code></pre>\n</li>\n<li><p><strong>Build &amp; Rendering:</strong> Early in development, I migrated the project from a purely static output to a server-rendered output (<code>output: &#39;server&#39;</code>) to accommodate the serverless API route for the contact form. I marked specific pages not requiring server-side logic for pre-rendering to maintain performance benefits.</p>\n</li>\n</ul>\n<p>This project demonstrates my strong understanding of modern web development principles, including JAMstack architecture, performance optimization, and the integration of disparate services (CMS, email) into a cohesive, serverless application.</p>\n","excerpt":"","more":"<p>This project is a real-life, high-performing site I built for a Fashion Stylist. For saradm.com, I leveraged the ease of use of Sanity.io headless CMS with the flexibility of Astro as a Frontend to deliver a great user experience for the visitor, the stylist making the content, and for myself maintaining the site. I deployed the site on Cloudflare Pages, utilizing serverless functions for the contact form which I built in TypeScript and integrated with Resend‚Äôs RESTful API.</p>\n<h2 id=\"Technical-Stack\"><a href=\"#Technical-Stack\" class=\"headerlink\" title=\"Technical Stack\"></a>Technical Stack</h2><ul>\n<li><strong>Frontend Framework:</strong> <a href=\"https://astro.build/\">Astro</a></li>\n<li><strong>UI Library:</strong> <a href=\"https://react.dev/\">React</a> (for interactive components)</li>\n<li><strong>Styling:</strong> <a href=\"https://tailwindcss.com/\">Tailwind CSS</a></li>\n<li><strong>Headless CMS:</strong> <a href=\"https://www.sanity.io/\">Sanity.io</a></li>\n<li><strong>Deployment &amp; Hosting:</strong> <a href=\"https://pages.cloudflare.com/\">Cloudflare Pages</a></li>\n<li><strong>Email Service:</strong> <a href=\"https://resend.com/\">Resend</a></li>\n</ul>\n<h2 id=\"Architectural-Highlights-Key-Features\"><a href=\"#Architectural-Highlights-Key-Features\" class=\"headerlink\" title=\"Architectural Highlights &amp; Key Features\"></a>Architectural Highlights &amp; Key Features</h2><p>I architected this project with the main goal of enabling the end-user (the stylist) to admin the contents, while keeping the site fast, maintainable, and scalable from a development perspective. To achieve this, I used a blend of static site generation and serverless computing.</p>\n<h3 id=\"1-Hybrid-Architecture-with-Astro\"><a href=\"#1-Hybrid-Architecture-with-Astro\" class=\"headerlink\" title=\"1. Hybrid Architecture with Astro\"></a>1. Hybrid Architecture with Astro</h3><p>I built the frontend core of the site with Astro, which I chose for its excellent performance and wide compatibility for different sources. I configured the architecture for server-side rendering to support dynamic API routes while pre-rendering static pages for optimal load times.<br>This hybrid approach provided the best of both worlds: the speed of static sites for content and the flexibility of server-rendered applications for user-interactable pages. Every post gets generated at build time from a queries to the sanity.io CMS.</p>\n<p>The site has two types of pages:</p>\n<ul>\n<li><strong>Static Pages:</strong> Astro statically generates most pages (<code>index</code>, <code>posts</code>, <code>[slug]</code>) at build time, ensuring near-instant delivery from Cloudflare‚Äôs edge network around the world.</li>\n<li><strong>Dynamic API Routes:</strong> I wrote a serverless API endpoint (<code>/api/contact.ts</code>) to handle form submissions without requiring a traditional backend server.</li>\n</ul>\n<h3 id=\"2-Headless-CMS-for-Content-Management\"><a href=\"#2-Headless-CMS-for-Content-Management\" class=\"headerlink\" title=\"2. Headless CMS for Content Management\"></a>2. Headless CMS for Content Management</h3><p>I used Sanity.io to manage all project content, including text and images. This decouples the content from the presentation layer, allowing the stylist to update their portfolio without needing my intervention, following the JAMstack philosophy. Astro fetches this content at build time to generate the static pages.</p>\n<p>Hosting all the images in Sanity.io allows me to use Sanity‚Äôs CDN to serve images at the right size and anywhere in the world.</p>\n<h3 id=\"3-Serverless-Contact-Form\"><a href=\"#3-Serverless-Contact-Form\" class=\"headerlink\" title=\"3. Serverless Contact Form\"></a>3. Serverless Contact Form</h3><p>To handle user inquiries, I implemented a secure and robust contact form:</p>\n<ul>\n<li><p><strong>Frontend:</strong> I used a React component (<code>ContactForm.jsx</code>) to provide a modern, interactive user experience with client-side validation. The component manages form state, handles user input, and communicates with the backend API.</p>\n</li>\n<li><p><strong>Backend:</strong> I wrote an Astro API route that acts as a serverless function deployed on Cloudflare. It receives the form data, validates it, and uses the Resend API to send the email.</p>\n</li>\n<li><p><strong>Security:</strong> I managed API keys and environment variables securely using Cloudflare‚Äôs environment variable system, accessing them via <code>locals.runtime.env</code> in the Astro backend to prevent exposure on the client-side.</p>\n</li>\n</ul>\n<h3 id=\"4-Responsive-Design-Image-Optimization\"><a href=\"#4-Responsive-Design-Image-Optimization\" class=\"headerlink\" title=\"4. Responsive Design &amp; Image Optimization\"></a>4. Responsive Design &amp; Image Optimization</h3><p>With users being all around the world and interested in fashion, a major focus for me was creating a visually consistent and responsive experience across all devices.</p>\n<ul>\n<li><strong>Tailwind CSS:</strong> I used a utility-first approach for rapid, maintainable styling. I configured custom styles to keep a specific color palette across the whole site in <code>tailwind.config.js</code>.</li>\n<li><strong>Responsive Image Loading:</strong> I used the Astro <code>Image</code> component to implement <code>srcset</code> and <code>sizes</code> attributes. This ensures that browsers download the most appropriately sized image based on the device‚Äôs viewport and resolution, significantly improving performance and reducing bandwidth.</li>\n<li><strong>Dynamic Layouts:</strong> I designed the project gallery with layouts that dynamically adjust based on content, such as aligning text based on the position of the corresponding image and different columns for big screens or mobile.</li>\n</ul>\n<h2 id=\"Development-Process-Problem-Solving\"><a href=\"#Development-Process-Problem-Solving\" class=\"headerlink\" title=\"Development Process &amp; Problem-Solving\"></a>Development Process &amp; Problem-Solving</h2><p>My development process was iterative, focusing on building features, fixing bugs, and continuous refinement.</p>\n<ul>\n<li><p><strong>Client-Side Interactivity:</strong> A key challenge I faced was implementing a tag-based filtering system on the <code>/posts</code> page that worked seamlessly with Astro‚Äôs view transitions. The initial script I wrote failed on navigation, but I resolved this by leveraging Astro‚Äôs <code>astro:page-load</code> event and the <code>is:inline</code> script attribute. This ensured the filter logic re-initialized correctly on each page load.</p>\n<pre><code class=\"highlight javascript\"><span class=\"comment\">// src/pages/posts.astro</span>\n<span class=\"keyword\">const</span> filterContainer = <span class=\"variable language_\">document</span>.<span class=\"title function_\">getElementById</span>(<span class=\"string\">&#x27;tag-filters&#x27;</span>);\n<span class=\"keyword\">const</span> postItems = <span class=\"variable language_\">document</span>.<span class=\"title function_\">querySelectorAll</span>(<span class=\"string\">&#x27;.post-item&#x27;</span>);\n\n<span class=\"keyword\">if</span> (filterContainer) &#123;\n  filterContainer.<span class=\"title function_\">addEventListener</span>(<span class=\"string\">&#x27;click&#x27;</span>, <span class=\"function\">(<span class=\"params\">e</span>) =&gt;</span> &#123;\n    <span class=\"keyword\">const</span> target = e.<span class=\"property\">target</span> <span class=\"keyword\">as</span> <span class=\"title class_\">HTMLElement</span>;\n    <span class=\"keyword\">if</span> (target.<span class=\"property\">classList</span>.<span class=\"title function_\">contains</span>(<span class=\"string\">&#x27;tag-button&#x27;</span>)) &#123;\n      <span class=\"comment\">// ... code to update active button style ...</span>\n\n      <span class=\"keyword\">const</span> selectedTag = target.<span class=\"property\">dataset</span>.<span class=\"property\">tag</span>;\n\n      postItems.<span class=\"title function_\">forEach</span>(<span class=\"function\"><span class=\"params\">item</span> =&gt;</span> &#123;\n        <span class=\"keyword\">const</span> post = item <span class=\"keyword\">as</span> <span class=\"title class_\">HTMLElement</span>;\n        <span class=\"keyword\">const</span> postTags = post.<span class=\"property\">dataset</span>.<span class=\"property\">tags</span> ? post.<span class=\"property\">dataset</span>.<span class=\"property\">tags</span>.<span class=\"title function_\">split</span>(<span class=\"string\">&#x27;,&#x27;</span>) : [];\n        \n        <span class=\"keyword\">if</span> (selectedTag === <span class=\"string\">&#x27;all&#x27;</span> || postTags.<span class=\"title function_\">includes</span>(<span class=\"title class_\">String</span>(selectedTag))) &#123;\n          post.<span class=\"property\">style</span>.<span class=\"property\">display</span> = <span class=\"string\">&#x27;block&#x27;</span>;\n        &#125; <span class=\"keyword\">else</span> &#123;\n          post.<span class=\"property\">style</span>.<span class=\"property\">display</span> = <span class=\"string\">&#x27;none&#x27;</span>;\n        &#125;\n      &#125;);\n    &#125;\n  &#125;);\n&#125;</code></pre>\n</li>\n<li><p><strong>Build &amp; Rendering:</strong> Early in development, I migrated the project from a purely static output to a server-rendered output (<code>output: &#39;server&#39;</code>) to accommodate the serverless API route for the contact form. I marked specific pages not requiring server-side logic for pre-rendering to maintain performance benefits.</p>\n</li>\n</ul>\n<p>This project demonstrates my strong understanding of modern web development principles, including JAMstack architecture, performance optimization, and the integration of disparate services (CMS, email) into a cohesive, serverless application.</p>\n"}],"PostAsset":[],"PostCategory":[],"PostTag":[],"Tag":[]}}